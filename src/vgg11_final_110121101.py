# -*- coding: utf-8 -*-
"""VGG11-Final-110121101

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BDYJitNlD_AbPiWMnqFSa95eeQnRiETF

# **ğŸ“š Huáº¥n luyá»‡n MÃ´ hÃ¬nh VGG11**

## **ğŸ¯ Má»¥c tiÃªu**
- XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n **mÃ´ hÃ¬nh VGG11** Ä‘á»ƒ **phÃ¢n loáº¡i áº£nh** trong táº­p dá»¯ liá»‡u **CIFAR-100**.
- Thá»±c hiá»‡n cÃ¡c bÆ°á»›c cÆ¡ báº£n:
  - **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**.
  - **TÄƒng cÆ°á»ng dá»¯ liá»‡u** (*Data Augmentation*).
  - **PhÃ¢n chia dá»¯ liá»‡u** thÃ nh cÃ¡c táº­p: Huáº¥n luyá»‡n, Validation, vÃ  Kiá»ƒm tra.
- ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh qua cÃ¡c chá»‰ sá»‘ quan trá»ng:
  - **Loss** (*HÃ m máº¥t mÃ¡t*).
  - **Accuracy** (*Äá»™ chÃ­nh xÃ¡c*).
  - **Thá»i gian huáº¥n luyá»‡n**.
- PhÃ¢n tÃ­ch káº¿t quáº£ thÃ´ng qua cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan:
  - Biá»ƒu Ä‘á»“ **Loss** vÃ  **Accuracy**.
  - **Confusion Matrix** (*Ma tráº­n nháº§m láº«n*).

## **ğŸš€ YÃªu cáº§u trÆ°á»›c khi báº¯t Ä‘áº§u**

> **Cáº¥u hÃ¬nh Google Colab vá»›i GPU**
- Truy cáº­p vÃ o menu **Runtime** (Thá»i gian cháº¡y).
- Chá»n **Change runtime type** (Thay Ä‘á»•i kiá»ƒu mÃ´i trÆ°á»ng).
- Trong má»¥c **Hardware accelerator** (TrÃ¬nh tÄƒng tá»‘c pháº§n cá»©ng), chá»n: **T4 GPU**.
- Nháº¥n nÃºt **Save** (LÆ°u) Ä‘á»ƒ lÆ°u thay Ä‘á»•i.

## **âš¡ Cháº¡y Ä‘oáº¡n mÃ£ dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ thá»±c hiá»‡n:**
"""

# 0.1. Import thÆ° viá»‡n PyTorch Ä‘á»ƒ kiá»ƒm tra GPU
import torch

# 0.2. XÃ¡c Ä‘á»‹nh thiáº¿t bá»‹ (device) Ä‘ang sá»­ dá»¥ng: "cuda" (GPU) náº¿u kháº£ dá»¥ng, ngÆ°á»£c láº¡i lÃ  "cpu"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 0.3. Kiá»ƒm tra náº¿u thiáº¿t bá»‹ lÃ  GPU
if device.type == 'cuda':
    # 0.3.1. Láº¥y tÃªn GPU Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng
    gpu_name = torch.cuda.get_device_name(0)
    # 0.3.2. Láº¥y tá»•ng dung lÆ°á»£ng bá»™ nhá»› GPU (VRAM) vÃ  chuyá»ƒn Ä‘á»•i sang Ä‘Æ¡n vá»‹ GB
    vram_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
    # 0.3.3. Hiá»ƒn thá»‹ thÃ´ng tin vá» GPU
    print(f"âœ… Äang sá»­ dá»¥ng GPU: {gpu_name}")
    print(f"ğŸ”¹ Tá»•ng bá»™ nhá»› GPU (VRAM): {vram_total:.2f} GB")
else:
    # 0.3.4. Náº¿u khÃ´ng cÃ³ GPU, thÃ´ng bÃ¡o sá»­ dá»¥ng CPU vÃ  yÃªu cáº§u báº­t GPU trong Google Colab
    print("âŒ Äang sá»­ dá»¥ng CPU. Vui lÃ²ng báº­t GPU trong Google Colab!")

"""# **1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng**

> Äá»ƒ chuáº©n bá»‹ cho viá»‡c xÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh, cáº§n thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
> - Náº¡p cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.
> - Káº¿t ná»‘i Google Drive (náº¿u dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trÃªn Drive).
> - XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c tá»‡p dá»¯ liá»‡u vÃ  táº£i chÃºng vÃ o chÆ°Æ¡ng trÃ¬nh.
> - KhÃ¡m phÃ¡ dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒu rÃµ cáº¥u trÃºc vÃ  ná»™i dung trÆ°á»›c khi huáº¥n luyá»‡n.

## **1.1. Import thÆ° viá»‡n cáº§n thiáº¿t**
"""

# Import thÆ° viá»‡n cÆ¡ báº£n
from google.colab import drive                                                   # LiÃªn káº¿t Google Drive
import torch                                                                     # ThÆ° viá»‡n PyTorch
import numpy as np                                                               # Xá»­ lÃ½ máº£ng
import pickle                                                                    # Äá»c/ghi file dá»¯ liá»‡u nhá»‹ phÃ¢n
import os                                                                        # Thao tÃ¡c vá»›i há»‡ thá»‘ng tá»‡p
import urllib.request
import tarfile

# Import thÆ° viá»‡n xá»­ lÃ½ vÃ  tÄƒng cÆ°á»ng dá»¯ liá»‡u
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader, random_split

# Import cÃ¡c module cho mÃ´ hÃ¬nh há»c sÃ¢u
import torch.nn as nn
import torch.optim as optim
from torch.amp import GradScaler, autocast

# CÃ¡c thÆ° viá»‡n há»— trá»£ khÃ¡c
import time                                                                      # Äo thá»i gian
import json                                                                      # LÆ°u trá»¯ dá»¯ liá»‡u
import matplotlib.pyplot as plt                                                  # Váº½ biá»ƒu Ä‘á»“
import pandas as pd                                                              # Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng
import random                                                                    # Xá»­ lÃ½ ngáº«u nhiÃªn
from collections import Counter                                                  # Äáº¿m táº§n suáº¥t
from ipywidgets import interact, widgets                                         # 1.3.8.
import matplotlib.pyplot as plt                                                  # 1.3.8.
import base64                                                                    # 1.7.
from io import BytesIO                                                           # 1.7.
from PIL import Image

# Má»¥c 8.
import matplotlib.pyplot as plt                                                  # ThÆ° viá»‡n váº½ biá»ƒu Ä‘á»“ cÆ¡ báº£n
import seaborn as sns                                                            # ThÆ° viá»‡n váº½ biá»ƒu Ä‘á»“ nÃ¢ng cao
import numpy as np                                                               # Xá»­ lÃ½ máº£ng sá»‘ há»c
import pandas as pd                                                              # Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay             # ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t

"""## **1.2. LiÃªn káº¿t Google Drive**

> LiÃªn káº¿t Google Drive Ä‘á»ƒ truy cáº­p vÃ  sá»­ dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trá»¯.
"""

# 1.2. LiÃªn káº¿t Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""## **1.3. Táº£i vÃ  thiáº¿t láº­p CIFAR-100**

> Khai bÃ¡o Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra Ä‘Æ°á»£c lÆ°u trá»¯ trong Google Drive.
"""

# 1.3.1. Táº£i vÃ  thiáº¿t láº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n táº­p dá»¯ liá»‡u
# ÄÆ°á»ng dáº«n URL chá»©a dá»¯ liá»‡u CIFAR-100
CIFAR100_URL = "https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz"

# ÄÆ°á»ng dáº«n thÆ° má»¥c lÆ°u trá»¯ dá»¯ liá»‡u
DATA_PATH = '/content/drive/MyDrive/'

def download_and_extract_cifar100(data_path, url):
    """
    HÃ m táº£i vÃ  giáº£i nÃ©n dá»¯ liá»‡u CIFAR-100.
    """
    if not os.path.exists(data_path):
        os.makedirs(data_path)

    # ÄÆ°á»ng dáº«n file nÃ©n
    tar_path = os.path.join(data_path, "cifar-100-python.tar.gz")

    # Táº£i file náº¿u chÆ°a tá»“n táº¡i
    if not os.path.exists(tar_path):
        print("Äang táº£i dá»¯ liá»‡u CIFAR-100...")
        urllib.request.urlretrieve(url, tar_path)
        print("Táº£i thÃ nh cÃ´ng.")
    else:
        print("File dá»¯ liá»‡u Ä‘Ã£ tá»“n táº¡i, bá» qua bÆ°á»›c táº£i.")

    # Giáº£i nÃ©n file
    print("Äang giáº£i nÃ©n dá»¯ liá»‡u...")
    with tarfile.open(tar_path, "r:gz") as tar:
        tar.extractall(path=data_path)
    print("Giáº£i nÃ©n thÃ nh cÃ´ng.")

    # XÃ¡c minh káº¿t quáº£
    extracted_path = os.path.join(data_path, 'cifar-100-python')
    if os.path.exists(extracted_path):
        print(f"Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c giáº£i nÃ©n táº¡i: {extracted_path}")
    else:
        print("CÃ³ lá»—i trong quÃ¡ trÃ¬nh giáº£i nÃ©n.")

# Gá»i hÃ m Ä‘á»ƒ táº£i vÃ  giáº£i nÃ©n dá»¯ liá»‡u
download_and_extract_cifar100(DATA_PATH, CIFAR100_URL)

# ÄÆ°á»ng dáº«n sau khi giáº£i nÃ©n
TRAIN_PATH = os.path.join(DATA_PATH, 'cifar-100-python', 'train')  # ÄÆ°á»ng dáº«n táº­p train
TEST_PATH = os.path.join(DATA_PATH, 'cifar-100-python', 'test')    # ÄÆ°á»ng dáº«n táº­p test
META_PATH = os.path.join(DATA_PATH, 'cifar-100-python', 'meta')    # ÄÆ°á»ng dáº«n meta
meta_path = os.path.join(DATA_PATH, 'cifar-100-python', 'meta')

print(f"ÄÆ°á»ng dáº«n Ä‘áº¿n táº­p huáº¥n luyá»‡n: {TRAIN_PATH}")
print(f"ÄÆ°á»ng dáº«n Ä‘áº¿n táº­p kiá»ƒm tra: {TEST_PATH}")
print(f"ÄÆ°á»ng dáº«n Ä‘áº¿n meta: {META_PATH}")

# 1.3.2. Liá»‡t kÃª cÃ¡c tá»‡p trong thÆ° má»¥c dá»¯ liá»‡u
# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c dá»¯ liá»‡u sau khi giáº£i nÃ©n
DATA_PATH = '/content/drive/MyDrive/cifar-100-python/'

# Liá»‡t kÃª cÃ¡c file trong thÆ° má»¥c
train_files = os.listdir(DATA_PATH)
print(f"CÃ¡c tá»‡p trong thÆ° má»¥c dá»¯ liá»‡u: {train_files}")

# 1.3.3. Táº£i dá»¯ liá»‡u huáº¥n luyá»‡n, kiá»ƒm tra vÃ  meta tá»« cÃ¡c tá»‡p pickle
with open(os.path.join(DATA_PATH, 'train'), 'rb') as f:
    train_data = pickle.load(f, encoding='bytes')                                # Táº£i dá»¯ liá»‡u huáº¥n luyá»‡n tá»« tá»‡p 'train'
with open(os.path.join(DATA_PATH, 'test'), 'rb') as f:
    test_data = pickle.load(f, encoding='bytes')                                 # Táº£i dá»¯ liá»‡u kiá»ƒm tra tá»« tá»‡p 'test'
with open(os.path.join(DATA_PATH, 'meta'), 'rb') as f:
    meta_data = pickle.load(f, encoding='bytes')                                 # Táº£i dá»¯ liá»‡u thÃ´ng tin lá»›p tá»« tá»‡p 'meta'
with open(meta_path, 'rb') as f:
    meta_data = pickle.load(f, encoding='bytes')                                 # Táº£i láº¡i dá»¯ liá»‡u meta, phá»¥c vá»¥ cho má»¥c 7

# 1.3.4. Hiá»ƒn thá»‹ thÃ´ng tin vá» sá»‘ lÆ°á»£ng áº£nh (cáº£i tiáº¿n)

# 1.3.4.1. TÃ­nh toÃ¡n sá»‘ lÆ°á»£ng áº£nh
num_train_images = len(train_data[b'data'])                                                   # Tá»•ng sá»‘ áº£nh trong táº­p huáº¥n luyá»‡n
num_test_images = len(test_data[b'data'])                                                     # Tá»•ng sá»‘ áº£nh trong táº­p kiá»ƒm tra
total_images = num_train_images + num_test_images                                             # Tá»•ng sá»‘ áº£nh

# 1.3.4.2. TÃ­nh tá»· lá»‡ pháº§n trÄƒm
train_percentage = (num_train_images / total_images) * 100                                    # Tá»· lá»‡ dá»¯ liá»‡u huáº¥n luyá»‡n
test_percentage = (num_test_images / total_images) * 100                                      # Tá»· lá»‡ dá»¯ liá»‡u kiá»ƒm tra

# 1.3.4.3. In thÃ´ng tin chi tiáº¿t
print(f"Tá»•ng sá»‘ áº£nh trong táº­p dá»¯ liá»‡u: {total_images}")
print(f"Tá»•ng sá»‘ áº£nh trong táº­p huáº¥n luyá»‡n: {num_train_images} ({train_percentage:.2f}%)")
print(f"Tá»•ng sá»‘ áº£nh trong táº­p kiá»ƒm tra: {num_test_images} ({test_percentage:.2f}%)\n")

# 1.3.4.4. Hiá»ƒn thá»‹ tá»· lá»‡ báº±ng biá»ƒu Ä‘á»“ trÃ²n
labels = ['Train Data', 'Test Data']
sizes = [num_train_images, num_test_images]
colors = ['skyblue', 'salmon']
explode = (0.1, 0)                                                                            # Ná»•i báº­t pháº§n Train Data

plt.figure(figsize=(8, 8))
plt.pie(
    sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors, explode=explode,
    wedgeprops={'edgecolor': 'black'}                                                         # Viá»n Ä‘en Ä‘á»ƒ ná»•i báº­t
)
plt.title("Tá»· lá»‡ dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra", fontsize=16, fontweight='bold')
plt.axis('equal')                                                                             # Äáº£m báº£o biá»ƒu Ä‘á»“ hÃ¬nh trÃ²n cÃ¢n Ä‘á»‘i
plt.show()

# 1.3.5. Äá»c thÃ´ng tin tÃªn cÃ¡c lá»›p vÃ  phÃ¢n loáº¡i chÃ­nh tá»« tá»‡p meta (tÄƒng khoáº£ng cÃ¡ch giá»¯a cÃ¡c cá»™t)

# 1.3.5.2. Láº¥y danh sÃ¡ch cÃ¡c loáº¡i con vÃ  loáº¡i lá»›n tá»« dá»¯ liá»‡u meta
fine_classes = meta_data[b'fine_label_names']                                                               # Danh sÃ¡ch tÃªn loáº¡i con (fine classes)
coarse_classes = meta_data[b'coarse_label_names']                                                           # Danh sÃ¡ch tÃªn loáº¡i lá»›n (coarse classes)

# 1.3.5.3. In tá»•ng sá»‘ loáº¡i lá»›n vÃ  loáº¡i con
total_fine_classes = len(fine_classes)                                                                      # Tá»•ng sá»‘ loáº¡i con
total_coarse_classes = len(coarse_classes)                                                                  # Tá»•ng sá»‘ loáº¡i lá»›n

print(f"Tá»•ng sá»‘ loáº¡i con (fine classes) trong táº­p dá»¯ liá»‡u: {total_fine_classes}")
print(f"Tá»•ng sá»‘ loáº¡i lá»›n (coarse classes) trong táº­p dá»¯ liá»‡u: {total_coarse_classes}\n")

# 1.3.5.4. Hiá»ƒn thá»‹ danh sÃ¡ch cÃ¡c loáº¡i lá»›n (coarse classes) theo dáº¡ng báº£ng (tÄƒng khoáº£ng cÃ¡ch)
print("Danh sÃ¡ch cÃ¡c loáº¡i lá»›p lá»›n (coarse classes):")
num_columns_coarse = 4                                                                                      # Sá»‘ cá»™t hiá»ƒn thá»‹ cho loáº¡i lá»›n
rows_coarse = total_coarse_classes // num_columns_coarse + (total_coarse_classes % num_columns_coarse > 0)  # TÃ­nh sá»‘ dÃ²ng

formatted_coarse_table = []                                                                                 # Danh sÃ¡ch lÆ°u báº£ng Ä‘Ã£ Ä‘á»‹nh dáº¡ng
for i in range(rows_coarse):
    row = []
    for j in range(num_columns_coarse):
        idx = i + j * rows_coarse
        if idx < total_coarse_classes:
            row.append(f"{idx:2}: {coarse_classes[idx].decode('utf-8'):<40}")                               # Format tÃªn lá»›p (Ä‘á»™ rá»™ng cá»‘ Ä‘á»‹nh 45 kÃ½ tá»±)
        else:
            row.append("")                                                                                  # ThÃªm Ã´ trá»‘ng náº¿u khÃ´ng Ä‘á»§ dá»¯ liá»‡u
    formatted_coarse_table.append(row)

# In danh sÃ¡ch cÃ¡c loáº¡i lá»›n theo tá»«ng dÃ²ng
for row in formatted_coarse_table:
    print("".join(row))                                                                                     # In tá»«ng dÃ²ng vá»›i khoáº£ng cÃ¡ch Ä‘á»“ng Ä‘á»u

# 1.3.5.5. Hiá»ƒn thá»‹ danh sÃ¡ch cÃ¡c loáº¡i con (fine classes) theo dáº¡ng báº£ng
print("\nDanh sÃ¡ch cÃ¡c loáº¡i lá»›p con (fine classes):")
num_columns_fine = 4                                                                                        # Sá»‘ cá»™t hiá»ƒn thá»‹ cho loáº¡i con
rows_fine = total_fine_classes // num_columns_fine + (total_fine_classes % num_columns_fine > 0)            # TÃ­nh sá»‘ dÃ²ng

formatted_fine_table = []                                                                                   # Danh sÃ¡ch lÆ°u báº£ng Ä‘Ã£ Ä‘á»‹nh dáº¡ng
for i in range(rows_fine):
    row = []
    for j in range(num_columns_fine):
        idx = i + j * rows_fine
        if idx < total_fine_classes:
            row.append(f"{idx:2}: {fine_classes[idx].decode('utf-8'):<25}")                                 # Format tÃªn lá»›p (Ä‘á»™ rá»™ng cá»‘ Ä‘á»‹nh 25 kÃ½ tá»±)
        else:
            row.append("")                                                                                  # ThÃªm Ã´ trá»‘ng náº¿u khÃ´ng Ä‘á»§ dá»¯ liá»‡u
    formatted_fine_table.append(row)

# In danh sÃ¡ch cÃ¡c loáº¡i con theo tá»«ng dÃ²ng
for row in formatted_fine_table:
    print("".join(row))                                                                                     # In tá»«ng dÃ²ng vá»›i khoáº£ng cÃ¡ch Ä‘á»“ng Ä‘á»u

# 1.3.6. Hiá»ƒn thá»‹ ngáº«u nhiÃªn cÃ¡c áº£nh tá»« táº­p huáº¥n luyá»‡n (cÃ³ thÃ´ng tin pixel)

class_names = meta_data[b'fine_label_names']                                                                    # Load danh sÃ¡ch tÃªn lá»›p con (fine classes)

# 1.3.6.1. Thiáº¿t láº­p hiá»ƒn thá»‹ 5 áº£nh ngáº«u nhiÃªn
fig, axes = plt.subplots(1, 5, figsize=(15, 3))                                                                 # Táº¡o khung hiá»ƒn thá»‹ vá»›i 5 cá»™t
for i in range(5):
    # 1.3.6.2. Chá»n ngáº«u nhiÃªn má»™t áº£nh tá»« táº­p huáº¥n luyá»‡n
    random_idx = random.randint(0, num_train_images - 1)                                                        # Chá»‰ sá»‘ ngáº«u nhiÃªn
    image = train_data[b'data'][random_idx].reshape(3, 32, 32).transpose(1, 2, 0)                               # Chuyá»ƒn Ä‘á»•i Ä‘á»‹nh dáº¡ng áº£nh
    label = train_data[b'fine_labels'][random_idx]                                                              # Láº¥y nhÃ£n tÆ°Æ¡ng á»©ng

    # 1.3.6.3. TÃ­nh thÃ´ng tin pixel
    mean_pixel = image.mean()                                                                                   # GiÃ¡ trá»‹ pixel trung bÃ¬nh
    min_pixel = image.min()                                                                                     # GiÃ¡ trá»‹ pixel nhá» nháº¥t
    max_pixel = image.max()                                                                                     # GiÃ¡ trá»‹ pixel lá»›n nháº¥t

    # 1.3.6.4. Hiá»ƒn thá»‹ áº£nh vÃ  nhÃ£n
    axes[i].imshow(image)                                                                                       # Hiá»ƒn thá»‹ áº£nh
    axes[i].axis('off')                                                                                         # Táº¯t khung viá»n xung quanh
    axes[i].set_title(
        f"{class_names[label].decode('utf-8')}\nMean: {mean_pixel:.1f}\nMin: {min_pixel}\nMax: {max_pixel}",
        fontsize=10                                                                                             # Äáº·t tiÃªu Ä‘á» vá»›i thÃ´ng tin pixel
    )

# 1.3.6.5. Äáº·t tiÃªu Ä‘á» chung cho toÃ n bá»™ biá»ƒu Ä‘á»“
plt.suptitle("Hiá»ƒn thá»‹ 5 áº£nh ngáº«u nhiÃªn tá»« táº­p huáº¥n luyá»‡n kÃ¨m thÃ´ng tin chi tiáº¿t vá» pixel", fontsize=16)
plt.tight_layout()                                                                                              # Äiá»u chá»‰nh khoáº£ng cÃ¡ch giá»¯a cÃ¡c áº£nh
plt.show()

# 1.3.7. Biá»ƒu Ä‘á»“ sá»‘ lÆ°á»£ng áº£nh trong má»—i lá»›p

# 1.3.7.1. Äáº¿m sá»‘ lÆ°á»£ng áº£nh theo tá»«ng lá»›p
labels = train_data[b'fine_labels']                                              # Láº¥y danh sÃ¡ch cÃ¡c nhÃ£n trong táº­p huáº¥n luyá»‡n
label_counts = Counter(labels)                                                   # Äáº¿m táº§n suáº¥t xuáº¥t hiá»‡n cá»§a tá»«ng nhÃ£n

# 1.3.7.2. Váº½ biá»ƒu Ä‘á»“ cá»™t thá»ƒ hiá»‡n sá»‘ lÆ°á»£ng áº£nh trong tá»«ng lá»›p
plt.figure(figsize=(12, 6))                                                      # KÃ­ch thÆ°á»›c biá»ƒu Ä‘á»“
plt.bar(label_counts.keys(), label_counts.values())                              # Táº¡o biá»ƒu Ä‘á»“ cá»™t
plt.xlabel('Lá»›p', fontsize=14)                                                   # NhÃ£n trá»¥c X
plt.ylabel('Sá»‘ lÆ°á»£ng áº£nh', fontsize=14)                                          # NhÃ£n trá»¥c Y
plt.title('Sá»‘ lÆ°á»£ng áº£nh trong má»—i lá»›p (Train Data)', fontsize=18)                # TiÃªu Ä‘á» biá»ƒu Ä‘á»“

# 1.3.7.3. TÃ¹y chá»‰nh nhÃ£n trá»¥c X
plt.xticks(
    ticks=list(label_counts.keys()),
    labels=[class_names[i].decode('utf-8') for i in label_counts.keys()],
    rotation=90                                                                  # Xoay nhÃ£n trá»¥c X 90 Ä‘á»™
)

# 1.3.7.4. CÄƒn chá»‰nh vÃ  hiá»ƒn thá»‹ biá»ƒu Ä‘á»“
plt.tight_layout()                                                               # CÄƒn chá»‰nh biá»ƒu Ä‘á»“ Ä‘á»ƒ khÃ´ng bá»‹ trÃ n khung
plt.show()

# 1.3.8. Hiá»ƒn thá»‹ áº£nh theo lá»±a chá»n cá»§a ngÆ°á»i dÃ¹ng (thÃªm khoáº£ng cÃ¡ch)

class_names = meta_data[b'fine_label_names']                                                             # Load danh sÃ¡ch tÃªn lá»›p con (fine classes)

# 1.3.8.1. ThÃªm mÃ´ táº£ phÃ­a trÃªn menu
print("Chá»n má»™t lá»›p tá»« danh sÃ¡ch bÃªn dÆ°á»›i Ä‘á»ƒ xem 5 áº£nh ngáº«u nhiÃªn thuá»™c lá»›p Ä‘Ã³:")

# 1.3.8.2. HÃ m hiá»ƒn thá»‹ áº£nh cá»§a má»™t lá»›p Ä‘Æ°á»£c chá»n
def show_images_for_class(class_name):
    # TÃ¬m chá»‰ sá»‘ cá»§a lá»›p Ä‘Æ°á»£c chá»n
    class_idx = [i for i, name in enumerate(class_names) if name.decode('utf-8') == class_name][0]

    # Láº¥y táº¥t cáº£ áº£nh thuá»™c lá»›p nÃ y
    class_images = [train_data[b'data'][idx].reshape(3, 32, 32).transpose(1, 2, 0)
                    for idx, label in enumerate(train_data[b'fine_labels']) if label == class_idx]

    # Hiá»ƒn thá»‹ 5 áº£nh ngáº«u nhiÃªn tá»« lá»›p
    fig, axes = plt.subplots(1, 5, figsize=(15, 3))
    plt.subplots_adjust(top=0.8)                                                                         # ThÃªm khoáº£ng cÃ¡ch phÃ­a trÃªn giá»¯a dropdown vÃ  áº£nh
    for i in range(5):
        axes[i].imshow(class_images[i])                                                                  # Hiá»ƒn thá»‹ áº£nh
        axes[i].axis('off')                                                                              # Táº¯t viá»n
        axes[i].set_title(class_name, fontsize=10)                                                       # TÃªn lá»›p

    # TiÃªu Ä‘á» chung
    plt.suptitle(f"5 áº£nh ngáº«u nhiÃªn tá»« lá»›p: {class_name}", fontsize=16)
    plt.show()

# 1.3.8.3. Dropdown menu Ä‘á»ƒ chá»n lá»›p
class_dropdown = widgets.Dropdown(
    options=[name.decode('utf-8') for name in class_names],
    description='Lá»›p:',
    style={'description_width': 'initial'}
)

# 1.3.8.4. TÃ­ch há»£p dropdown vá»›i hÃ m hiá»ƒn thá»‹ áº£nh
interact(show_images_for_class, class_name=class_dropdown)

# 1.3.9. Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng áº£nh cá»§a tá»«ng lá»›p báº±ng giao diá»‡n tÆ°Æ¡ng tÃ¡c

# 1.3.9.1. HÃ m hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng áº£nh cho má»™t lá»›p cá»¥ thá»ƒ
def show_class_image_count(class_name):
    # TÃ¬m chá»‰ sá»‘ cá»§a lá»›p Ä‘Æ°á»£c chá»n
    class_idx = [i for i, name in enumerate(class_names) if name.decode('utf-8') == class_name][0]

    # Äáº¿m sá»‘ lÆ°á»£ng áº£nh thuá»™c lá»›p Ä‘Ã³
    count = sum(1 for label in train_data[b'fine_labels'] if label == class_idx)
    print(f"Sá»‘ lÆ°á»£ng áº£nh trong lá»›p '{class_name}': {count}")

# 1.3.9.2. Dropdown menu Ä‘á»ƒ chá»n lá»›p
class_dropdown = widgets.Dropdown(
    options=[name.decode('utf-8') for name in class_names],
    description='Chá»n lá»›p:',
    style={'description_width': 'initial'}
)

# 1.3.9.3. TÃ­ch há»£p vá»›i giao diá»‡n tÆ°Æ¡ng tÃ¡c
interact(show_class_image_count, class_name=class_dropdown)

# 1.3.10. Giao diá»‡n tÆ°Æ¡ng tÃ¡c Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ phÃ¢n bá»‘ giÃ¡ trá»‹ pixel

# 1.3.10.1. ThÃªm mÃ´ táº£ phÃ­a trÃªn menu
print("Chá»n má»™t lá»›p tá»« danh sÃ¡ch bÃªn dÆ°á»›i Ä‘á»ƒ xem 5 áº£nh ngáº«u nhiÃªn thuá»™c lá»›p Ä‘Ã³:")

# 1.3.10.2. HÃ m váº½ biá»ƒu Ä‘á»“ phÃ¢n bá»‘ giÃ¡ trá»‹ pixel cá»§a má»™t lá»›p
def plot_pixel_distribution(class_name):
    # TÃ¬m chá»‰ sá»‘ cá»§a lá»›p Ä‘Æ°á»£c chá»n
    class_idx = [i for i, name in enumerate(class_names) if name.decode('utf-8') == class_name][0]

    # Láº¥y táº¥t cáº£ áº£nh thuá»™c lá»›p Ä‘Æ°á»£c chá»n
    class_images = [train_data[b'data'][idx] for idx, label in enumerate(train_data[b'fine_labels']) if label == class_idx]
    pixel_values = np.concatenate(class_images).flatten()  # Káº¿t há»£p táº¥t cáº£ áº£nh vÃ  lÃ m pháº³ng

    # Váº½ biá»ƒu Ä‘á»“ phÃ¢n bá»‘
    plt.figure(figsize=(10, 6))
    plt.hist(pixel_values, bins=50, color='skyblue', edgecolor='black')
    plt.xlabel('GiÃ¡ trá»‹ pixel', fontsize=14)
    plt.ylabel('Táº§n suáº¥t', fontsize=14)
    plt.title(f'PhÃ¢n bá»‘ giÃ¡ trá»‹ pixel cá»§a lá»›p: {class_name}', fontsize=16, fontweight='bold')
    plt.show()

# 1.3.10.3. Dropdown menu Ä‘á»ƒ chá»n lá»›p
class_dropdown = widgets.Dropdown(
    options=[name.decode('utf-8') for name in class_names],
    description='Chá»n lá»›p:',
    style={'description_width': 'initial'}
)

# 1.3.10.4. TÃ­ch há»£p vá»›i giao diá»‡n tÆ°Æ¡ng tÃ¡c
interact(plot_pixel_distribution, class_name=class_dropdown)

"""## **1.4. Táº¡o lá»›p Dataset tÃ¹y chá»‰nh**
- Äá»ƒ xá»­ lÃ½ dá»¯ liá»‡u CIFAR-100 hiá»‡u quáº£ hÆ¡n, cáº§n xÃ¢y dá»±ng má»™t lá»›p Dataset tÃ¹y chá»‰nh.  
> Lá»›p nÃ y sáº½ giÃºp:
  - Quáº£n lÃ½ dá»¯ liá»‡u áº£nh vÃ  nhÃ£n tÆ°Æ¡ng á»©ng.
  - Táº¡o Ä‘iá»u kiá»‡n thuáº­n lá»£i cho viá»‡c sá»­ dá»¥ng trong DataLoader Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.

- VÃ­ dá»¥ dá»… hiá»ƒu hÆ¡n, lá»›p nÃ y giá»‘ng nhÆ° **ngÆ°á»i quáº£n lÃ½**, giÃºp chia dá»¯ liá»‡u thÃ nh tá»«ng **áº£nh vÃ  nhÃ£n** Ä‘á»ƒ mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c.
"""

# 1.4. XÃ¢y dá»±ng lá»›p Dataset cho CIFAR-100

# 1.4.1. Äá»‹nh nghÄ©a lá»›p Dataset cho CIFAR-100
class CIFAR100Dataset(Dataset):
    # 1.4.2. Khá»Ÿi táº¡o lá»›p vá»›i cÃ¡c tham sá»‘: dá»¯ liá»‡u, nhÃ£n vÃ  hÃ m xá»­ lÃ½ áº£nh (náº¿u cÃ³)
    def __init__(self, data, labels, transform=None):
        self.data = data                                                                                  # LÆ°u trá»¯ dá»¯ liá»‡u áº£nh
        self.labels = labels                                                                              # LÆ°u trá»¯ nhÃ£n tÆ°Æ¡ng á»©ng vá»›i tá»«ng áº£nh
        self.transform = transform                                                                        # LÆ°u trá»¯ hÃ m xá»­ lÃ½ áº£nh (náº¿u cÃ³)

    # 1.4.3. Tráº£ vá» tá»•ng sá»‘ máº«u trong táº­p dá»¯ liá»‡u
    def __len__(self):
        return len(self.data)                                                                             # Tráº£ vá» sá»‘ lÆ°á»£ng máº«u trong dá»¯ liá»‡u

    # 1.4.4. Tráº£ vá» má»™t áº£nh vÃ  nhÃ£n tÆ°Æ¡ng á»©ng táº¡i vá»‹ trÃ­ idx
    def __getitem__(self, idx):
        # 1.4.5. Láº¥y áº£nh táº¡i chá»‰ sá»‘ idx vÃ  chuyá»ƒn Ä‘á»•i thÃ nh Ä‘á»‹nh dáº¡ng (3, 32, 32) Ä‘á»ƒ phÃ¹ há»£p vá»›i PyTorch
        image = self.data[idx].reshape(3, 32, 32).transpose(1, 2, 0)                                      # Chuyá»ƒn áº£nh tá»« Ä‘á»‹nh dáº¡ng (32, 32, 3) thÃ nh (3, 32, 32)

        # 1.4.6. Láº¥y nhÃ£n cá»§a áº£nh táº¡i chá»‰ sá»‘ idx
        label = self.labels[idx]                                                                          # NhÃ£n tÆ°Æ¡ng á»©ng vá»›i áº£nh

        # 1.4.7. Náº¿u cÃ³ hÃ m xá»­ lÃ½ áº£nh (transform), Ã¡p dá»¥ng lÃªn áº£nh
        if self.transform:
            image = self.transform(image)                                                                 # Ãp dá»¥ng biáº¿n Ä‘á»•i (nhÆ° chuáº©n hÃ³a, xoay áº£nh, v.v.)

        # 1.4.8. Tráº£ vá» áº£nh vÃ  nhÃ£n (áº£nh Ä‘Æ°á»£c chuyá»ƒn thÃ nh Tensor)
        return image, label                                                                               # Tráº£ vá» áº£nh vÃ  nhÃ£n, áº£nh cÃ³ thá»ƒ Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½

"""## **1.5. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**

TrÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh, cáº§n táº£i dá»¯ liá»‡u vÃ  xá»­ lÃ½ Ä‘á»ƒ Ä‘áº£m báº£o mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n.  
> CÃ¡c bÆ°á»›c thá»±c hiá»‡n:
  - **Táº£i dá»¯ liá»‡u**: Láº¥y dá»¯ liá»‡u tá»« cÃ¡c tá»‡p `pickle` cá»§a táº­p CIFAR-100.
  - **TÄƒng cÆ°á»ng dá»¯ liá»‡u**: Ãp dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° láº­t áº£nh, cáº¯t áº£nh Ä‘á»ƒ lÃ m phong phÃº táº­p huáº¥n luyá»‡n.
  - **Chuáº©n hÃ³a dá»¯ liá»‡u**: Chuyá»ƒn giÃ¡ trá»‹ pixel vá» khoáº£ng [-1, 1] Ä‘á»ƒ cáº£i thiá»‡n quÃ¡ trÃ¬nh há»c cá»§a mÃ´ hÃ¬nh.

"""

# 1.5.1. Táº£i dá»¯ liá»‡u tá»« tá»‡p pickle
with open(TRAIN_PATH, 'rb') as f:
    train_data = pickle.load(f, encoding='bytes')                                # Táº£i táº­p dá»¯ liá»‡u huáº¥n luyá»‡n tá»« tá»‡p pickle
with open(TEST_PATH, 'rb') as f:
    test_data = pickle.load(f, encoding='bytes')                                 # Táº£i táº­p dá»¯ liá»‡u kiá»ƒm tra tá»« tá»‡p pickle

# 1.5.2. TÄƒng cÆ°á»ng dá»¯ liá»‡u cho táº­p huáº¥n luyá»‡n
train_transform = transforms.Compose([
    transforms.ToPILImage(),                                                     # Chuyá»ƒn áº£nh tá»« dáº¡ng sá»‘ sang áº£nh PIL (há»— trá»£ xá»­ lÃ½ áº£nh dá»… dÃ ng hÆ¡n)
    transforms.Resize((32, 32)),                                                 # Thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh vá» 32x32 (Ä‘áº£m báº£o Ä‘á»“ng nháº¥t kÃ­ch thÆ°á»›c)
    transforms.RandomHorizontalFlip(),                                           # Láº­t ngang áº£nh ngáº«u nhiÃªn Ä‘á»ƒ tÄƒng cÆ°á»ng dá»¯ liá»‡u
    transforms.RandomCrop(32, padding=4),                                        # Cáº¯t áº£nh ngáº«u nhiÃªn vá»›i viá»n Ä‘á»‡m 4 pixel
    transforms.ToTensor(),                                                       # Chuyá»ƒn áº£nh tá»« PIL sang Tensor (Ä‘á»‹nh dáº¡ng PyTorch yÃªu cáº§u)
    transforms.Normalize((0.5, 0.5, 0.5),                                        # Chuáº©n hÃ³a giÃ¡ trá»‹ pixel (mean cho tá»«ng kÃªnh RGB)
                         (0.5, 0.5, 0.5))                                        # Chuáº©n hÃ³a giÃ¡ trá»‹ pixel (std cho tá»«ng kÃªnh RGB)
])

# 1.5.3. Xá»­ lÃ½ dá»¯ liá»‡u kiá»ƒm tra
test_transform = transforms.Compose([
    transforms.ToPILImage(),                                                     # Chuyá»ƒn áº£nh tá»« dáº¡ng sá»‘ sang áº£nh PIL
    transforms.Resize((32, 32)),                                                 # Thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh vá» 32x32
    transforms.ToTensor(),                                                       # Chuyá»ƒn áº£nh tá»« PIL sang Tensor
    transforms.Normalize((0.5, 0.5, 0.5),                                        # Chuáº©n hÃ³a giÃ¡ trá»‹ pixel (mean cho tá»«ng kÃªnh RGB)
                         (0.5, 0.5, 0.5))                                        # Chuáº©n hÃ³a giÃ¡ trá»‹ pixel (std cho tá»«ng kÃªnh RGB)
])

"""## **1.6. Khá»Ÿi táº¡o DataLoader**

#### **Thiáº¿t láº­p thÃ´ng sá»‘:**

1. **Chia táº­p dá»¯ liá»‡u:**
   > - **Táº­p huáº¥n luyá»‡n (train):** Chiáº¿m 90% dá»¯ liá»‡u.
   - **Táº­p kiá»ƒm tra (validation):** Chiáº¿m 10% dá»¯ liá»‡u.

2. **Sá»­ dá»¥ng DataLoader:**
   > - **Táº­p huáº¥n luyá»‡n:** XÃ¡o trá»™n dá»¯ liá»‡u Ä‘á»ƒ tÄƒng tÃ­nh ngáº«u nhiÃªn, giÃºp cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh.
   - **Táº­p kiá»ƒm tra vÃ  validation:** Dá»¯ liá»‡u giá»¯ nguyÃªn thá»© tá»± Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n trong Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.

#### **CÃ´ng thá»©c tÃ­nh sá»‘ batch**

Sá»‘ batch trong má»—i táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÃ­nh nhÆ° sau:
$$
\text{Sá»‘ batch} = \frac{\text{Tá»•ng sá»‘ máº«u}}{\text{Batch size}}
$$


#### **VÃ­ dá»¥ tÃ­nh toÃ¡n:**

- **Táº­p huáº¥n luyá»‡n:**
$$
\text{Sá»‘ batch (train)} = \frac{45000}{128} = 351.5625 = 352
$$

- **Táº­p kiá»ƒm tra:**
$$
\text{Sá»‘ batch (validation)} = \frac{5000}{128}  =  39.0625 = 40
$$


#### **Káº¿t quáº£:**
- Táº­p huáº¥n luyá»‡n: **352** batch.
- Táº­p kiá»ƒm tra: **40** batch.

"""

# 1.6.1. Thiáº¿t láº­p kÃ­ch thÆ°á»›c batch
batch_size = 128

# 1.6.2. HÃ m chuáº©n bá»‹ DataLoader
def prepare_data_loaders(train_data, test_data, train_transform, test_transform, val_split=0.1):
    # Táº¡o Dataset cho táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra
    train_dataset = CIFAR100Dataset(train_data[b'data'], train_data[b'fine_labels'], transform=train_transform)
    test_dataset = CIFAR100Dataset(test_data[b'data'], test_data[b'fine_labels'], transform=test_transform)

    # Chia táº­p huáº¥n luyá»‡n thÃ nh training set vÃ  validation set
    train_size = int((1 - val_split) * len(train_dataset))                                                      # 90% cho táº­p huáº¥n luyá»‡n
    val_size = len(train_dataset) - train_size                                                                  # 10% cho táº­p validation
    train_data, val_data = random_split(train_dataset, [train_size, val_size])                                  # Chia táº­p dá»¯ liá»‡u

    # Táº¡o DataLoader cho tá»«ng táº­p
    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)                                  # Shuffle tÄƒng tÃ­nh ngáº«u nhiÃªn
    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)                                     # Validation giá»¯ nguyÃªn thá»© tá»±
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)                                # Test giá»¯ nguyÃªn thá»© tá»±

    return train_loader, val_loader, test_loader                                                                # Tráº£ vá» cÃ¡c DataLoader

# 1.6.3. Chuáº©n bá»‹ DataLoader

# 1.6.3.1. Gá»i hÃ m Ä‘á»ƒ táº¡o DataLoader cho táº­p huáº¥n luyá»‡n, validation vÃ  kiá»ƒm tra
train_loader, val_loader, test_loader = prepare_data_loaders(
    train_data, test_data, train_transform, test_transform
)

# 1.6.3.2. In thÃ´ng tin sá»‘ batch cá»§a tá»«ng táº­p
print(f"Sá»‘ batch trong táº­p huáº¥n luyá»‡n: {len(train_loader)}")
print(f"Sá»‘ batch trong táº­p validation: {len(val_loader)}")
print(f"Sá»‘ batch trong táº­p kiá»ƒm tra: {len(test_loader)}")

"""# **2. Äá»‹nh nghÄ©a mÃ´ hÃ¬nh VGG11**

### **A. Má»¥c tiÃªu**
> Thiáº¿t káº¿ mÃ´ hÃ¬nh **VGG11** Ä‘á»ƒ phÃ¢n loáº¡i áº£nh cÃ³ kÃ­ch thÆ°á»›c **32 Ã— 32** thuá»™c táº­p dá»¯ liá»‡u **CIFAR-100** thÃ nh **100 lá»›p**.

### **B. Tá»•ng quan vá» kiáº¿n trÃºc**

#### **1. Khá»‘i trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (Feature Extractor):**
- Bao gá»“m **5 khá»‘i chÃ­nh**, má»—i khá»‘i thá»±c hiá»‡n cÃ¡c bÆ°á»›c:
  
 > 1. **Convolution (Conv2D):** TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh.
  2. **Batch Normalization:** Chuáº©n hÃ³a dá»¯ liá»‡u giá»¯a cÃ¡c lá»›p Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ há»™i tá»¥.
  3. **Activation (ReLU):** ÄÆ°a phi tuyáº¿n tÃ­nh vÃ o máº¡ng Ä‘á»ƒ mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p.
  4. **MaxPooling:** Giáº£m kÃ­ch thÆ°á»›c khÃ´ng gian áº£nh (háº¡ máº«u) Ä‘á»ƒ giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n.

- Sá»‘ lÆ°á»£ng kÃªnh (channels) tÄƒng dáº§n qua cÃ¡c khá»‘i:
  $$
  3 \to 64 \to 128 \to 256 \to 512
  $$

#### **2. Khá»‘i phÃ¢n loáº¡i (Classifier):**
- Gá»“m **3 lá»›p Fully Connected (FC):**
  > 1. **FC1:** Chuyá»ƒn Ä‘áº§u vÃ o tá»« khá»‘i trÃ­ch xuáº¥t thÃ nh vector pháº³ng.
  2. **FC2:** Há»c cÃ¡c Ä‘áº·c trÆ°ng sÃ¢u hÆ¡n.
  3. **FC3:** Dá»± Ä‘oÃ¡n 100 lá»›p tá»« táº­p CIFAR-100.
- **Dropout:** ÄÆ°á»£c sá»­ dá»¥ng giá»¯a cÃ¡c lá»›p Ä‘á»ƒ giáº£m hiá»‡n tÆ°á»£ng overfitting báº±ng cÃ¡ch ngáº«u nhiÃªn bá» qua má»™t sá»‘ neuron.

### **C. TÃ³m gá»n**
> Má»¥c nÃ y Ä‘á»‹nh nghÄ©a mÃ´ hÃ¬nh **VGG11**, gá»“m khá»‘i trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÃ  khá»‘i phÃ¢n loáº¡i Ä‘á»ƒ xá»­ lÃ½ vÃ  dá»± Ä‘oÃ¡n áº£nh thuá»™c **100 lá»›p** cá»§a táº­p dá»¯ liá»‡u **CIFAR-100.**


"""

# 2.1. Äá»‹nh nghÄ©a kiáº¿n trÃºc VGG11
class VGG11(nn.Module):
    def __init__(self, num_classes=100):  # num_classes máº·c Ä‘á»‹nh lÃ  100 (CIFAR-100)
        super(VGG11, self).__init__()

        # 2.1.1. Khá»‘i trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (Feature Extractor)
        self.features = nn.Sequential(
            # Block 1: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cÆ¡ báº£n
            nn.Conv2d(3, 64, kernel_size=3, padding=1),    # Conv: Äáº§u vÃ o 3 kÃªnh (RGB) -> 64 kÃªnh
            nn.BatchNorm2d(64),                            # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPooling: Giáº£m kÃ­ch thÆ°á»›c khÃ´ng gian (2x2)

            # Block 2: NÃ¢ng cao Ä‘áº·c trÆ°ng
            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv: 64 -> 128 kÃªnh
            nn.BatchNorm2d(128),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPooling: (2x2)

            # Block 3: Báº¯t Ä‘áº§u trÃ­ch xuáº¥t chi tiáº¿t hÆ¡n
            nn.Conv2d(128, 256, kernel_size=3, padding=1), # Conv: 128 -> 256 kÃªnh
            nn.BatchNorm2d(256),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.Conv2d(256, 256, kernel_size=3, padding=1), # Conv: 256 -> 256
            nn.BatchNorm2d(256),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPooling: (2x2)

            # Block 4: Äáº·c trÆ°ng chi tiáº¿t cáº¥p cao hÆ¡n
            nn.Conv2d(256, 512, kernel_size=3, padding=1), # Conv: 256 -> 512 kÃªnh
            nn.BatchNorm2d(512),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Conv: 512 -> 512
            nn.BatchNorm2d(512),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPooling: (2x2)

            # Block 5: Äáº·c trÆ°ng chi tiáº¿t cáº¥p cao nháº¥t
            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Conv: 512 -> 512 kÃªnh
            nn.BatchNorm2d(512),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Conv: 512 -> 512
            nn.BatchNorm2d(512),                           # Chuáº©n hÃ³a Batch
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPooling: (2x2)
        )

        # 2.1.2. Khá»‘i phÃ¢n loáº¡i (Classifier)
        self.classifier = nn.Sequential(
            nn.Linear(512 * 1 * 1, 4096),                  # FC1: Nháº­n Ä‘áº§u vÃ o tá»« khá»‘i Ä‘áº·c trÆ°ng
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.Dropout(0.5),                               # Dropout: Giáº£m overfitting
            nn.Linear(4096, 4096),                         # FC2: Tiáº¿p tá»¥c há»c
            nn.ReLU(),                                     # HÃ m kÃ­ch hoáº¡t ReLU
            nn.Dropout(0.5),                               # Dropout: Giáº£m overfitting
            nn.Linear(4096, num_classes),                  # FC3: Dá»± Ä‘oÃ¡n 100 lá»›p
        )

    def forward(self, x):
        x = self.features(x)                               # Cháº¡y qua khá»‘i trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
        x = x.view(x.size(0), -1)                          # Flatten (tráº£i pháº³ng) tensor
        x = self.classifier(x)                             # Cháº¡y qua khá»‘i phÃ¢n loáº¡i
        return x

"""# **3. Thiáº¿t láº­p cáº¥u trÃºc VGG11**

### **A. Má»¥c tiÃªu**

1. **Khá»Ÿi táº¡o mÃ´ hÃ¬nh:** Táº¡o mÃ´ hÃ¬nh `VGG11` vá»›i 100 lá»›p (táº­p CIFAR-100) vÃ  Ä‘áº£m báº£o mÃ´ hÃ¬nh Ä‘Æ°á»£c chuyá»ƒn sang thiáº¿t bá»‹ phÃ¹ há»£p.
2. **Äá»‹nh nghÄ©a hÃ m máº¥t mÃ¡t:** Sá»­ dá»¥ng `CrossEntropyLoss` Ä‘á»ƒ tÃ­nh toÃ¡n sai sá»‘ dá»±a trÃªn dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh vÃ  nhÃ£n thá»±c táº¿.
3. **Khá»Ÿi táº¡o bá»™ tá»‘i Æ°u hÃ³a:** Sá»­ dá»¥ng thuáº­t toÃ¡n **SGD (Stochastic Gradient Descent)** vá»›i cÃ¡c tham sá»‘:
   - **Learning rate (lr):** \( 0.01 \).
   - **Momentum:** \( 0.9 \) Ä‘á»ƒ tÄƒng tÃ­nh á»•n Ä‘á»‹nh khi cáº­p nháº­t trá»ng sá»‘.
   - **Weight decay:** \( 5e^{-4} \) Ä‘á»ƒ giáº£m hiá»‡n tÆ°á»£ng overfitting.
4. **Lá»‹ch trÃ¬nh giáº£m tá»‘c Ä‘á»™ há»c (Scheduler):** Sá»­ dá»¥ng **Cosine Annealing** Ä‘á»ƒ giáº£m dáº§n tá»‘c Ä‘á»™ há»c (\( lr \)) trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
5. **Gradient Scaling:** Sá»­ dá»¥ng `GradScaler` Ä‘á»ƒ há»— trá»£ **Mixed Precision Training**, tÄƒng hiá»‡u suáº¥t khi cháº¡y trÃªn GPU.

### **B. TÃ³m gá»n:**
> Má»¥c nÃ y thá»±c hiá»‡n viá»‡c thiáº¿t láº­p Ä‘áº§y Ä‘á»§ cÃ¡c thÃ nh pháº§n cáº§n thiáº¿t Ä‘á»ƒ sáºµn sÃ ng huáº¥n luyá»‡n mÃ´ hÃ¬nh `VGG11`.

"""

# 3.1.2. Khá»Ÿi táº¡o mÃ´ hÃ¬nh
model = VGG11(num_classes=100).to(device)                                        # Khá»Ÿi táº¡o mÃ´ hÃ¬nh VGG11 vá»›i 100 lá»›p (CIFAR-100) vÃ  chuyá»ƒn mÃ´ hÃ¬nh lÃªn GPU

# 3.1.3. Äá»‹nh nghÄ©a hÃ m máº¥t mÃ¡t
criterion = nn.CrossEntropyLoss()                                                # Sá»­ dá»¥ng hÃ m máº¥t mÃ¡t CrossEntropy Ä‘á»ƒ Ä‘o lÆ°á»ng sai sá»‘ cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a lá»›p

# 3.1.4. Khá»Ÿi táº¡o bá»™ tá»‘i Æ°u hÃ³a SGD
optimizer = optim.SGD(
    model.parameters(),                                                          # Truyá»n cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh vÃ o bá»™ tá»‘i Æ°u hÃ³a
    lr=0.01,                                                                     # Thiáº¿t láº­p tá»‘c Ä‘á»™ há»c ban Ä‘áº§u (learning rate)
    momentum=0.9,                                                                # Sá»­ dá»¥ng momentum Ä‘á»ƒ giáº£m dao Ä‘á»™ng trong viá»‡c cáº­p nháº­t trá»ng sá»‘
    weight_decay=5e-4                                                            # ThÃªm weight decay (regularization) Ä‘á»ƒ giáº£m hiá»‡n tÆ°á»£ng overfitting
)

# 3.1.5. Thiáº¿t láº­p lá»‹ch trÃ¬nh há»c
scheduler = optim.lr_scheduler.CosineAnnealingLR(
    optimizer,                                                                   # Bá»™ tá»‘i Æ°u hÃ³a mÃ  lá»‹ch trÃ¬nh há»c sáº½ Ä‘iá»u chá»‰nh
    T_max=400                                                                    # Tá»•ng sá»‘ epoch Ä‘á»ƒ giáº£m learning rate tá»« giÃ¡ trá»‹ ban Ä‘áº§u vá» gáº§n 0
)

# 3.1.6. Gradient Scaling Ä‘á»ƒ há»— trá»£ Mixed Precision Training
scaler = GradScaler()                                                            # Sá»­ dá»¥ng Gradient Scaling Ä‘á»ƒ há»— trá»£ tÃ­nh toÃ¡n vá»›i Mixed Precision (float16), giáº£m lá»—i sá»‘ há»c

"""# **4. Thiáº¿t láº­p hÃ m huáº¥n luyá»‡n**

## **4.1. HÃ m huáº¥n luyá»‡n tá»«ng epoch**

### **A. Má»¥c tiÃªu**
1. **Huáº¥n luyá»‡n mÃ´ hÃ¬nh:**
   - Sá»­ dá»¥ng dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ tá»‘i Æ°u hÃ³a trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh.
   - Ãp dá»¥ng ká»¹ thuáº­t Mixed Precision Training Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t tÃ­nh toÃ¡n.
2. **Theo dÃµi tiáº¿n trÃ¬nh:**
   - TÃ­nh toÃ¡n loss trung bÃ¬nh cá»§a tá»«ng batch trong epoch.
   - Ghi log loss sau má»—i 100 bÆ°á»›c Ä‘á»ƒ theo dÃµi hiá»‡u suáº¥t mÃ´ hÃ¬nh trong thá»i gian thá»±c.

### **B. Quy trÃ¬nh thá»±c hiá»‡n**
1. **Chuyá»ƒn sang cháº¿ Ä‘á»™ huáº¥n luyá»‡n:**
   - Äáº·t mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ `train()` Ä‘á»ƒ kÃ­ch hoáº¡t gradient vÃ  tÃ­nh toÃ¡n cáº­p nháº­t trá»ng sá»‘.
2. **Xá»­ lÃ½ dá»¯ liá»‡u:**
   - Chuyá»ƒn batch dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  nhÃ£n thá»±c táº¿ tá»« CPU/GPU sang thiáº¿t bá»‹ phÃ¹ há»£p.
   - Sá»­ dá»¥ng `autocast` Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n Mixed Precision.
3. **Cáº­p nháº­t trá»ng sá»‘:**
   - TÃ­nh gradient dá»±a trÃªn loss.
   - Sá»­ dá»¥ng `optimizer` vÃ  `scaler` Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh.
4. **Ghi log:**
   - Sau má»—i 100 bÆ°á»›c (batch), in ra giÃ¡ trá»‹ loss Ä‘á»ƒ theo dÃµi tiáº¿n trÃ¬nh huáº¥n luyá»‡n.
5. **TÃ­nh toÃ¡n káº¿t quáº£:**
   - Tráº£ vá» loss trung bÃ¬nh trÃªn táº¥t cáº£ cÃ¡c batch trong epoch.

### **C. TÃ³m gá»n**
> Pháº§n nÃ y xÃ¢y dá»±ng hÃ m huáº¥n luyá»‡n theo tá»«ng epoch, vá»›i má»¥c tiÃªu giáº£m loss vÃ  tá»‘i Æ°u hÃ³a trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh báº±ng Mixed Precision Training.
"""

# 4.1. HÃ m huáº¥n luyá»‡n cho tá»«ng epoch

def train_epoch(model, train_loader, criterion, optimizer, scaler):
    # 4.1.1. Báº­t cháº¿ Ä‘á»™ huáº¥n luyá»‡n cho mÃ´ hÃ¬nh
    model.train()                                                                   # Äá»ƒ mÃ´ hÃ¬nh cÃ³ thá»ƒ tÃ­nh toÃ¡n vÃ  cáº­p nháº­t cÃ¡c giÃ¡ trá»‹ cáº§n thiáº¿t

    # 4.1.2. Táº¡o biáº¿n lÆ°u tá»•ng loss
    running_loss = 0                                                                # DÃ¹ng Ä‘á»ƒ theo dÃµi tá»•ng lá»—i (loss) trong suá»‘t epoch

    # 4.1.3. Xá»­ lÃ½ tá»«ng nhÃ³m dá»¯ liá»‡u (batch) trong táº­p huáº¥n luyá»‡n
    for step, (images, labels) in enumerate(train_loader):
        # 4.1.3.1. ÄÆ°a áº£nh vÃ  nhÃ£n sang GPU hoáº·c CPU Ä‘á»ƒ xá»­ lÃ½
        images, labels = images.to(device), labels.to(device)

        # 4.1.3.2. Dá»± Ä‘oÃ¡n káº¿t quáº£ vÃ  tÃ­nh lá»—i
        with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):  # Há»— trá»£ tÄƒng tá»‘c xá»­ lÃ½ náº¿u dÃ¹ng GPU
            outputs = model(images)                                                 # Dá»± Ä‘oÃ¡n nhÃ£n tá»« áº£nh
            loss = criterion(outputs, labels)                                       # TÃ­nh lá»—i giá»¯a káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ  nhÃ£n tháº­t

        # 4.1.3.3. Cáº­p nháº­t mÃ´ hÃ¬nh dá»±a trÃªn lá»—i
        optimizer.zero_grad()                                                       # XÃ³a giÃ¡ trá»‹ lá»—i cÅ© Ä‘á»ƒ báº¯t Ä‘áº§u tÃ­nh toÃ¡n má»›i
        scaler.scale(loss).backward()                                               # TÃ­nh toÃ¡n thay Ä‘á»•i cáº§n thiáº¿t (gradient) dá»±a trÃªn lá»—i
        scaler.step(optimizer)                                                      # Thay Ä‘á»•i cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh dá»±a trÃªn tÃ­nh toÃ¡n
        scaler.update()                                                             # Chuáº©n bá»‹ cho láº§n tÃ­nh toÃ¡n tiáº¿p theo

        # 4.1.3.4. LÆ°u láº¡i lá»—i Ä‘á»ƒ tÃ­nh trung bÃ¬nh sau
        running_loss += loss.item()

        # 4.1.3.5. Sau má»—i 100 nhÃ³m dá»¯ liá»‡u, in thÃ´ng tin lá»—i Ä‘á»ƒ ngÆ°á»i dÃ¹ng theo dÃµi
        if (step + 1) % 100 == 0:
            print(f"BÆ°á»›c [{step + 1}/{len(train_loader)}], Loss: {loss.item():.4f}")

    # 4.1.4. Tráº£ vá» lá»—i trung bÃ¬nh trÃªn toÃ n bá»™ dá»¯ liá»‡u cá»§a epoch
    return running_loss / len(train_loader)                                          # DÃ¹ng lá»—i trung bÃ¬nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ káº¿t quáº£ huáº¥n luyá»‡n

"""## **4.2. HÃ m Ä‘Ã¡nh giÃ¡ táº­p validation**

### **A. Má»¥c tiÃªu**
1. **ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t:**
   - TÃ­nh toÃ¡n Ä‘á»™ chÃ­nh xÃ¡c (accuracy) vÃ  loss trung bÃ¬nh trÃªn táº­p validation.
   - ÄÃ¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh dá»±a trÃªn dá»¯ liá»‡u khÃ´ng náº±m trong táº­p huáº¥n luyá»‡n.
2. **Tá»‘i Æ°u hiá»‡u nÄƒng:**
   - Sá»­ dá»¥ng `torch.no_grad()` Ä‘á»ƒ táº¯t gradient, giáº£m tiÃªu tá»‘n bá»™ nhá»› vÃ  tÄƒng tá»‘c Ä‘á»™ Ä‘Ã¡nh giÃ¡.
   - Káº¿t há»£p Mixed Precision (`autocast`) Ä‘á»ƒ tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ trÃªn GPU.

### **B. Quy trÃ¬nh thá»±c hiá»‡n**
1. **Chuyá»ƒn sang cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡:**
   - Äáº·t mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ `eval()` Ä‘á»ƒ vÃ´ hiá»‡u hÃ³a dropout vÃ  batch normalization, Ä‘áº£m báº£o Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c.
2. **Duyá»‡t qua tá»«ng batch:**
   - Chuyá»ƒn dá»¯ liá»‡u vÃ  nhÃ£n tá»« CPU/GPU sang thiáº¿t bá»‹ phÃ¹ há»£p.
   - Sá»­ dá»¥ng `autocast` Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n Mixed Precision.
3. **TÃ­nh toÃ¡n loss vÃ  Ä‘á»™ chÃ­nh xÃ¡c:**
   - Loss Ä‘Æ°á»£c tÃ­nh báº±ng hÃ m `criterion` giá»¯a Ä‘áº§u ra dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh vÃ  nhÃ£n thá»±c táº¿.
   - Äá»™ chÃ­nh xÃ¡c Ä‘Æ°á»£c tÃ­nh dá»±a trÃªn sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng chia cho tá»•ng sá»‘ máº«u.
4. **Káº¿t quáº£:**
   - Tráº£ vá» loss trung bÃ¬nh vÃ  Ä‘á»™ chÃ­nh xÃ¡c trÃªn toÃ n bá»™ táº­p validation.

### **C. TÃ³m gá»n**
> Pháº§n nÃ y xÃ¢y dá»±ng hÃ m Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation Ä‘á»ƒ Ä‘o lÆ°á»ng loss trung bÃ¬nh vÃ  Ä‘á»™ chÃ­nh xÃ¡c, há»— trá»£ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh.
"""

# 4.2. HÃ m Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation

def evaluate(model, val_loader, criterion):
    # 4.2.1. Äáº·t mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡
    model.eval()                                                                        # Táº¯t cháº¿ Ä‘á»™ huáº¥n luyá»‡n Ä‘á»ƒ khÃ´ng tÃ­nh toÃ¡n vÃ  cáº­p nháº­t cÃ¡c giÃ¡ trá»‹ trá»ng sá»‘

    # 4.2.2. Khá»Ÿi táº¡o cÃ¡c biáº¿n Ä‘á»ƒ theo dÃµi lá»—i vÃ  Ä‘á»™ chÃ­nh xÃ¡c
    running_loss = 0                                                                    # Tá»•ng lá»—i Ä‘á»ƒ tÃ­nh lá»—i trung bÃ¬nh
    correct = 0                                                                         # Tá»•ng sá»‘ dá»± Ä‘oÃ¡n Ä‘Ãºng
    total = 0                                                                           # Tá»•ng sá»‘ máº«u trong táº­p validation

    # 4.2.3. KhÃ´ng tÃ­nh gradient Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»› vÃ  tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½
    with torch.no_grad():                                                               # KhÃ´ng lÆ°u láº¡i thÃ´ng tin gradient
        # Láº·p qua tá»«ng nhÃ³m dá»¯ liá»‡u (batch) trong táº­p validation
        for images, labels in val_loader:
            # 4.2.3.1. Chuyá»ƒn áº£nh vÃ  nhÃ£n sang GPU hoáº·c CPU
            images, labels = images.to(device), labels.to(device)

            # 4.2.3.2. Dá»± Ä‘oÃ¡n káº¿t quáº£ vÃ  tÃ­nh lá»—i
            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):  # Há»— trá»£ tÄƒng tá»‘c náº¿u dÃ¹ng GPU
                outputs = model(images)                                                 # Dá»± Ä‘oÃ¡n nhÃ£n tá»« áº£nh
                loss = criterion(outputs, labels)                                       # TÃ­nh lá»—i giá»¯a káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿

            # 4.2.3.3. TÃ­nh tá»•ng lá»—i
            running_loss += loss.item()                                                 # Cá»™ng dá»“n lá»—i cá»§a batch hiá»‡n táº¡i

            # 4.2.3.4. TÃ­nh sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng
            _, predicted = outputs.max(1)                                               # Láº¥y nhÃ£n cÃ³ xÃ¡c suáº¥t cao nháº¥t
            total += labels.size(0)                                                     # Cá»™ng tá»•ng sá»‘ máº«u trong batch
            correct += predicted.eq(labels).sum().item()                                # Cá»™ng sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng

    # 4.2.4. TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c
    accuracy = 100.0 * correct / total                                                  # Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn tá»•ng sá»‘ máº«u (%)

    # 4.2.5. Tráº£ vá» lá»—i trung bÃ¬nh vÃ  Ä‘á»™ chÃ­nh xÃ¡c
    return running_loss / len(val_loader), accuracy                                     # Lá»—i trung bÃ¬nh vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a toÃ n bá»™ táº­p validation

"""# **5. Huáº¥n luyá»‡n mÃ´ hÃ¬nh VGG11**

## **A. Má»¥c tiÃªu**
1. **Tá»‘i Æ°u hÃ³a trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh** qua nhiá»u epoch.
2. **ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t trÃªn táº­p validation** Ä‘á»ƒ theo dÃµi sá»± cáº£i thiá»‡n.
3. **Ghi nháº­n cÃ¡c thÃ´ng sá»‘ quan trá»ng** nhÆ° loss, Ä‘á»™ chÃ­nh xÃ¡c, vÃ  thá»i gian huáº¥n luyá»‡n.
4. **LÆ°u tráº¡ng thÃ¡i mÃ´ hÃ¬nh (checkpoint)** khi Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y.

## **B. Quy trÃ¬nh**

### **1. Khá»Ÿi táº¡o**
- CÃ¡c thÃ nh pháº§n cáº§n thiáº¿t Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh:
  - **Optimizer:** Tá»‘i Æ°u trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh.
  - **Scheduler:** Äiá»u chá»‰nh learning rate trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
  - **Criterion:** HÃ m máº¥t mÃ¡t Ä‘á»ƒ tÃ­nh toÃ¡n sai sá»‘.
- Danh sÃ¡ch ghi nháº­n thÃ´ng tin:
  - `train_losses`: Ghi láº¡i loss trÃªn táº­p huáº¥n luyá»‡n.
  - `val_losses`: Ghi láº¡i loss trÃªn táº­p validation.
  - `val_accuracies`: Ghi láº¡i Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation.
  - `epoch_times`: Ghi láº¡i thá»i gian huáº¥n luyá»‡n má»—i epoch.

### **2. VÃ²ng láº·p qua cÃ¡c epoch**
1. **Báº¯t Ä‘áº§u epoch:**
   - Ghi nháº­n thá»i gian báº¯t Ä‘áº§u.
2. **Huáº¥n luyá»‡n trÃªn táº­p train:**
   - Chuyá»ƒn mÃ´ hÃ¬nh sang cháº¿ Ä‘á»™ `train()`.
   - TÃ­nh toÃ¡n loss qua cÃ¡c batch vÃ  cáº­p nháº­t trá»ng sá»‘ báº±ng `optimizer`.
3. **ÄÃ¡nh giÃ¡ trÃªn táº­p validation:**
   - Chuyá»ƒn mÃ´ hÃ¬nh sang cháº¿ Ä‘á»™ `eval()`.
   - TÃ­nh toÃ¡n loss vÃ  Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation.
4. **Ghi nháº­n vÃ  hiá»ƒn thá»‹ káº¿t quáº£:**
   - Hiá»ƒn thá»‹ loss vÃ  Ä‘á»™ chÃ­nh xÃ¡c cho tá»«ng epoch.
   - Ghi nháº­n thá»i gian huáº¥n luyá»‡n epoch.
5. **So sÃ¡nh vÃ  lÆ°u tráº¡ng thÃ¡i mÃ´ hÃ¬nh:**
   - So sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation:
     - LÆ°u checkpoint náº¿u Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t.

### **3. LÆ°u checkpoint**
- **Tráº¡ng thÃ¡i lÆ°u:**
  - Trá»ng sá»‘ mÃ´ hÃ¬nh.
  - Tráº¡ng thÃ¡i cá»§a optimizer vÃ  scheduler.
  - Epoch hiá»‡n táº¡i.
  - Äá»™ chÃ­nh xÃ¡c tá»‘t nháº¥t.

## **C. TÃ³m gá»n**
> VÃ²ng láº·p nÃ y thá»±c hiá»‡n huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ qua nhiá»u epoch, ghi nháº­n cÃ¡c thÃ´ng sá»‘ quan trá»ng vÃ  lÆ°u tráº¡ng thÃ¡i mÃ´ hÃ¬nh khi Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t. ÄÃ¢y lÃ  bÆ°á»›c tá»‘i Æ°u trá»ng sá»‘ mÃ´ hÃ¬nh Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t tá»‘t nháº¥t.

"""

# 5.1. Sá»‘ lÆ°á»£ng epoch cáº§n huáº¥n luyá»‡n
num_epochs = 400                                                                 # Tá»•ng sá»‘ epoch Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh
checkpoint_path = '/content/drive/MyDrive/vgg11_best_checkpoint.pth'             # ÄÆ°á»ng dáº«n lÆ°u checkpoint cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
best_accuracy = 0                                                                # Biáº¿n lÆ°u Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t

# 5.2. Danh sÃ¡ch lÆ°u thÃ´ng tin huáº¥n luyá»‡n
train_losses = []                                                                # LÆ°u loss trung bÃ¬nh cá»§a tá»«ng epoch trong táº­p huáº¥n luyá»‡n
val_losses = []                                                                  # LÆ°u loss trung bÃ¬nh cá»§a tá»«ng epoch trong táº­p validation
val_accuracies = []                                                              # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation sau má»—i epoch
epoch_times = []                                                                 # LÆ°u thá»i gian cháº¡y cá»§a tá»«ng epoch

# 5.3. VÃ²ng láº·p huáº¥n luyá»‡n
for epoch in range(num_epochs):  # Láº·p qua tá»«ng epoch
    print(f"**Epoch [{epoch + 1}/{num_epochs}]**")                               # In thÃ´ng tin epoch hiá»‡n táº¡i

    # 5.3.1. Äo thá»i gian báº¯t Ä‘áº§u epoch
    start_time = time.time()                                                     # Ghi láº¡i thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u epoch

    # 5.3.2. Gá»i hÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p huáº¥n luyá»‡n
    train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler)  # Gá»i hÃ m huáº¥n luyá»‡n cho tá»«ng epoch

    # 5.3.3. Gá»i hÃ m Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation
    val_loss, val_accuracy = evaluate(model, val_loader, criterion)              # Gá»i hÃ m Ä‘Ã¡nh giÃ¡ trÃªn táº­p validation

    # 5.3.4. TÃ­nh thá»i gian thá»±c hiá»‡n epoch
    epoch_time = time.time() - start_time                                        # TÃ­nh thá»i gian hoÃ n thÃ nh epoch

    # 5.3.5. LÆ°u káº¿t quáº£ huáº¥n luyá»‡n cá»§a epoch
    train_losses.append(train_loss)                                              # LÆ°u loss trung bÃ¬nh cá»§a táº­p huáº¥n luyá»‡n
    val_losses.append(val_loss)                                                  # LÆ°u loss trung bÃ¬nh cá»§a táº­p validation
    val_accuracies.append(val_accuracy)                                          # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation
    epoch_times.append(epoch_time)                                               # LÆ°u thá»i gian thá»±c hiá»‡n epoch

    # 5.3.6. Hiá»ƒn thá»‹ thÃ´ng tin káº¿t quáº£ cá»§a epoch
    print(f"Loss huáº¥n luyá»‡n: {train_loss:.4f}")                                  # Hiá»ƒn thá»‹ loss trung bÃ¬nh trÃªn táº­p huáº¥n luyá»‡n
    print(f"Loss kiá»ƒm tra: {val_loss:.4f}, Äá»™ chÃ­nh xÃ¡c: {val_accuracy:.2f}%")   # Hiá»ƒn thá»‹ loss vÃ  Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation
    print(f"Thá»i gian cho epoch [{epoch + 1}]: {epoch_time:.2f} giÃ¢y")           # Hiá»ƒn thá»‹ thá»i gian thá»±c hiá»‡n epoch

    # 5.3.7. Cáº­p nháº­t tráº¡ng thÃ¡i mÃ´ hÃ¬nh náº¿u Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t
    if val_accuracy > best_accuracy:                                             # Kiá»ƒm tra náº¿u Ä‘á»™ chÃ­nh xÃ¡c hiá»‡n táº¡i tá»‘t hÆ¡n
        best_accuracy = val_accuracy                                             # Cáº­p nháº­t Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t
        torch.save({
            'epoch': epoch + 1,                                                  # LÆ°u sá»‘ thá»© tá»± cá»§a epoch
            'model_state_dict': model.state_dict(),                              # LÆ°u tráº¡ng thÃ¡i mÃ´ hÃ¬nh
            'optimizer_state_dict': optimizer.state_dict(),                      # LÆ°u tráº¡ng thÃ¡i bá»™ tá»‘i Æ°u
            'scheduler_state_dict': scheduler.state_dict(),                      # LÆ°u tráº¡ng thÃ¡i lá»‹ch trÃ¬nh learning rate
            'scaler_state_dict': scaler.state_dict(),                            # LÆ°u tráº¡ng thÃ¡i Gradient Scaler
            'best_accuracy': best_accuracy                                       # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t
        }, checkpoint_path)  # LÆ°u táº¡i Ä‘Æ°á»ng dáº«n Ä‘Ã£ Ä‘á»‹nh nghÄ©a
        print(f"Checkpoint Ä‘Æ°á»£c lÆ°u vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t: {best_accuracy:.2f}%")

    # 5.3.8. Cáº­p nháº­t learning rate theo scheduler
    scheduler.step()                                                             # Äiá»u chá»‰nh tá»‘c Ä‘á»™ há»c theo lá»‹ch trÃ¬nh

"""# **6. LÆ°u káº¿t quáº£ huáº¥n luyá»‡n**

### **A. Má»¥c tiÃªu**
1. LÆ°u láº¡i thÃ´ng tin káº¿t quáº£ huáº¥n luyá»‡n Ä‘á»ƒ phá»¥c vá»¥ phÃ¢n tÃ­ch hoáº·c sá»­ dá»¥ng sau nÃ y:
   - **Train losses:** GiÃ¡ trá»‹ lá»—i trung bÃ¬nh trÃªn táº­p huáº¥n luyá»‡n qua tá»«ng epoch.
   - **Validation losses:** GiÃ¡ trá»‹ lá»—i trung bÃ¬nh trÃªn táº­p validation qua tá»«ng epoch.
   - **Validation accuracies:** Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation qua tá»«ng epoch.
   - **Epoch times:** Thá»i gian thá»±c hiá»‡n má»—i epoch.
   - **Best accuracy:** Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c trÃªn táº­p validation.
2. Äáº£m báº£o viá»‡c lÆ°u file JSON nhanh chÃ³ng, tiá»‡n lá»£i vÃ  dá»… dÃ ng chia sáº».

### **B. Quy trÃ¬nh**
1. Äáº·t tÃªn file há»£p lÃ½: `training_results.json` Ä‘á»ƒ thá»ƒ hiá»‡n ná»™i dung file.
2. Sá»­ dá»¥ng `json.dump` Ä‘á»ƒ ghi thÃ´ng tin káº¿t quáº£ vÃ o file JSON.
3. Hiá»ƒn thá»‹ thÃ´ng bÃ¡o khi lÆ°u file thÃ nh cÃ´ng, kÃ¨m Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘á»ƒ kiá»ƒm tra nhanh hiá»‡u quáº£ mÃ´ hÃ¬nh.

### **C. TÃ³m gá»n**
> Pháº§n nÃ y lÆ°u thÃ´ng tin huáº¥n luyá»‡n (loss, Ä‘á»™ chÃ­nh xÃ¡c, thá»i gian) vÃ o file JSON Ä‘á»ƒ tiá»‡n phÃ¢n tÃ­ch vÃ  theo dÃµi hiá»‡u quáº£ mÃ´ hÃ¬nh.
"""

# 6.1. ÄÆ°á»ng dáº«n lÆ°u file JSON
output_path = '/content/drive/MyDrive/training_results.json'                     # LÆ°u file json vá»›i tÃªn file training_results.json

# 6.2. LÆ°u dá»¯ liá»‡u huáº¥n luyá»‡n ra file JSON
with open(output_path, 'w') as f:                                                # Má»Ÿ file á»Ÿ cháº¿ Ä‘á»™ ghi
    json.dump({
        "train_losses": train_losses,                                            # Danh sÃ¡ch loss trung bÃ¬nh trÃªn táº­p huáº¥n luyá»‡n
        "val_losses": val_losses,                                                # Danh sÃ¡ch loss trung bÃ¬nh trÃªn táº­p validation
        "val_accuracies": val_accuracies,                                        # Danh sÃ¡ch Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation
        "epoch_times": epoch_times,                                              # Danh sÃ¡ch thá»i gian thá»±c hiá»‡n tá»«ng epoch
        "best_accuracy": max(val_accuracies)                                     # Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c
    }, f)

# 6.3. ThÃ´ng bÃ¡o khi hoÃ n táº¥t lÆ°u file
print(f"Dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_path}")                      # ThÃ´ng bÃ¡o file JSON Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng
print(f"Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c: {max(val_accuracies):.2f}%")             # Hiá»ƒn thá»‹ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t

"""# **7. Kiá»ƒm thá»­ mÃ´ hÃ¬nh**

> **LÆ°u Ã½ quan trá»ng:**
  - Äáº£m báº£o báº¡n Ä‘Ã£ cháº¡y thÃ nh cÃ´ng cÃ¡c má»¥c sau:
    - **1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng**
    - **2. Äá»‹nh nghÄ©a mÃ´ hÃ¬nh VGG11**
    - **3. Thiáº¿t láº­p cáº¥u trÃºc VGG11**
  - TrÆ°á»›c khi tiáº¿p tá»¥c vá»›i cÃ¡c bÆ°á»›c dÆ°á»›i Ä‘Ã¢y!

## **7.1. Táº£i tÃªn lá»›p tá»« file meta**
- Äá»c danh sÃ¡ch **tÃªn lá»›p nhá» (fine labels)** vÃ  **tÃªn lá»›p lá»›n (coarse labels)** tá»« file meta Ä‘Æ°á»£c lÆ°u sáºµn.
- ÄÃ¢y lÃ  cÃ¡c lá»›p mÃ  mÃ´ hÃ¬nh sáº½ dá»± Ä‘oÃ¡n.
"""

# 7.1. Táº£i tÃªn lá»›p tá»« file meta
class_names = [name.decode('utf-8') for name in meta_data[b'fine_label_names']]          # Danh sÃ¡ch 100 lá»›p nhá» (fine labels)
coarse_names = [name.decode('utf-8') for name in meta_data[b'coarse_label_names']]       # Danh sÃ¡ch 20 lá»›p lá»›n (coarse labels)

"""## **7.2. HÃ m táº£i mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u**
- **Chá»©c nÄƒng:** Táº£i mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« file checkpoint.
- **Quy trÃ¬nh thá»±c hiá»‡n:**
  1. Táº¡o má»™t mÃ´ hÃ¬nh má»›i dá»±a trÃªn cáº¥u trÃºc Ä‘Ã£ Ä‘á»‹nh nghÄ©a (VGG11 vá»›i 100 lá»›p).
  2. Táº£i trá»ng sá»‘ vÃ  tráº¡ng thÃ¡i cá»§a mÃ´ hÃ¬nh tá»« file checkpoint.
  3. ÄÆ°a mÃ´ hÃ¬nh sang thiáº¿t bá»‹ phÃ¹ há»£p (GPU hoáº·c CPU).
  4. Äáº·t mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡ (**eval**) Ä‘á»ƒ chuáº©n bá»‹ cho dá»± Ä‘oÃ¡n.
"""

# 7.2. HÃ m táº£i mÃ´ hÃ¬nh tá»« checkpoint

checkpoint_path = '/content/drive/MyDrive/vgg11_best_checkpoint.pth'                     # ÄÆ°á»ng dáº«n Ä‘Ã£ lÆ°u mÃ´ hÃ¬nh

def load_model(checkpoint_path, num_classes=100):
    """
    Táº£i mÃ´ hÃ¬nh tá»« checkpoint Ä‘Ã£ lÆ°u.
    """
    model = VGG11(num_classes=num_classes)                                               # Táº¡o mÃ´ hÃ¬nh VGG11 vá»›i sá»‘ lá»›p lÃ  100
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)     # Táº£i checkpoint tá»« file
    model.load_state_dict(checkpoint['model_state_dict'])                                # Náº¡p tráº¡ng thÃ¡i mÃ´ hÃ¬nh tá»« checkpoint
    model.to(device)                                                                     # Chuyá»ƒn mÃ´ hÃ¬nh sang GPU hoáº·c CPU tÃ¹y thuá»™c vÃ o thiáº¿t bá»‹
    model.eval()                                                                         # Äáº·t mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡
    return model

"""## **7.3. HÃ m tiá»n xá»­ lÃ½ áº£nh**
- **Chá»©c nÄƒng:** Chuáº©n bá»‹ áº£nh Ä‘áº§u vÃ o Ä‘á»ƒ Ä‘Æ°a vÃ o mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n.
- **Quy trÃ¬nh thá»±c hiá»‡n:**
  1. Äá»c áº£nh tá»« Ä‘Æ°á»ng dáº«n Ä‘Æ°á»£c cung cáº¥p vÃ  chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng RGB.
  2. Thá»±c hiá»‡n cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½:
     - Resize áº£nh vá» kÃ­ch thÆ°á»›c chuáº©n (32x32).
     - Chuyá»ƒn Ä‘á»•i áº£nh sang Tensor Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i PyTorch.
     - Chuáº©n hÃ³a cÃ¡c giÃ¡ trá»‹ pixel vá» pháº¡m vi [-1, 1].
  3. Tráº£ vá» áº£nh gá»‘c vÃ  áº£nh Ä‘Ã£ qua xá»­ lÃ½.
"""

# 7.3. HÃ m tiá»n xá»­ lÃ½ áº£nh
def preprocess_image(image_path):
    """
    Tiá»n xá»­ lÃ½ áº£nh: Resize, chuyá»ƒn Ä‘á»•i sang Tensor, chuáº©n hÃ³a.
    """
    transform = transforms.Compose([
        transforms.Resize((32, 32)),                                                     # Resize áº£nh vá» kÃ­ch thÆ°á»›c 32x32
        transforms.ToTensor(),                                                           # Chuyá»ƒn áº£nh sang dáº¡ng Tensor
        transforms.Normalize((0.5, 0.5, 0.5),                                            # Chuáº©n hÃ³a giÃ¡ trá»‹ pixel (mean)
                             (0.5, 0.5, 0.5))                                            # Chuáº©n hÃ³a giÃ¡ trá»‹ pixel (std)
    ])
    image = Image.open(image_path).convert('RGB')                                        # Má»Ÿ áº£nh vÃ  chuyá»ƒn sang Ä‘á»‹nh dáº¡ng RGB
    return image, transform(image).unsqueeze(0).to(device)                               # Tráº£ vá» áº£nh gá»‘c vÃ  áº£nh Tensor Ä‘Ã£ chuáº©n hÃ³a

"""## **7.4. HÃ m dá»± Ä‘oÃ¡n lá»›p cá»§a áº£nh**
- **Chá»©c nÄƒng:** Dá»± Ä‘oÃ¡n lá»›p nhá» vÃ  lá»›p lá»›n cá»§a má»™t áº£nh.
- **Quy trÃ¬nh thá»±c hiá»‡n:**
  1. Tiá»n xá»­ lÃ½ áº£nh báº±ng cÃ¡ch gá»i hÃ m `preprocess_image`.
  2. ÄÆ°a áº£nh Ä‘Ã£ xá»­ lÃ½ vÃ o mÃ´ hÃ¬nh vÃ  láº¥y Ä‘áº§u ra dá»± Ä‘oÃ¡n.
  3. XÃ¡c Ä‘á»‹nh lá»›p dá»± Ä‘oÃ¡n (lá»›p nhá») dá»±a trÃªn chá»‰ sá»‘ xÃ¡c suáº¥t cao nháº¥t.
  4. Dá»±a trÃªn lá»›p nhá», xÃ¡c Ä‘á»‹nh lá»›p lá»›n tÆ°Æ¡ng á»©ng (theo chá»‰ sá»‘).
  5. Tráº£ vá» thÃ´ng tin áº£nh, lá»›p nhá», vÃ  lá»›p lá»›n Ä‘Ã£ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n.
"""

# 7.4. HÃ m dá»± Ä‘oÃ¡n lá»›p cá»§a áº£nh
def predict_image(model, image_path):
    """
    Dá»± Ä‘oÃ¡n lá»›p cá»§a áº£nh vÃ  tráº£ vá» thÃ´ng tin:
    - áº¢nh gá»‘c, kÃ­ch thÆ°á»›c áº£nh sau chuáº©n hÃ³a, chá»‰ sá»‘ lá»›p dá»± Ä‘oÃ¡n, tÃªn lá»›p nhá», vÃ  lá»›p lá»›n.
    """
    original_image, processed_image = preprocess_image(image_path)                       # Tiá»n xá»­ lÃ½ áº£nh
    with torch.no_grad():                                                                # Táº¯t tÃ­nh toÃ¡n gradient
        output = model(processed_image)                                                  # Dá»± Ä‘oÃ¡n Ä‘áº§u ra tá»« mÃ´ hÃ¬nh
        _, predicted = output.max(1)                                                     # Láº¥y chá»‰ sá»‘ lá»›p cÃ³ xÃ¡c suáº¥t cao nháº¥t
    predicted_index = predicted.item()                                                   # Chá»‰ sá»‘ lá»›p dá»± Ä‘oÃ¡n
    predicted_class = class_names[predicted_index]                                       # Láº¥y tÃªn lá»›p tá»« chá»‰ sá»‘
    predicted_coarse_class = coarse_names[predicted_index // 5]                          # Láº¥y tÃªn lá»›p lá»›n tá»« chá»‰ sá»‘
    return original_image, processed_image.size(), predicted_index, predicted_class, predicted_coarse_class

"""## **7.5. HÃ m xá»­ lÃ½ vÃ  hiá»ƒn thá»‹ káº¿t quáº£**
- **Chá»©c nÄƒng:** Xá»­ lÃ½ file áº£nh Ä‘Æ°á»£c ngÆ°á»i dÃ¹ng táº£i lÃªn vÃ  hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n.
- **Quy trÃ¬nh thá»±c hiá»‡n:**
  1. Nháº­n file áº£nh Ä‘Æ°á»£c táº£i lÃªn tá»« ngÆ°á»i dÃ¹ng thÃ´ng qua giao diá»‡n.
  2. LÆ°u file áº£nh vÃ o bá»™ nhá»› táº¡m Ä‘á»ƒ sá»­ dá»¥ng.
  3. Hiá»ƒn thá»‹ thÃ´ng bÃ¡o "Äang tiáº¿n hÃ nh dá»± Ä‘oÃ¡n..." Ä‘á»ƒ bÃ¡o hiá»‡u há»‡ thá»‘ng Ä‘ang xá»­ lÃ½.
  4. Gá»i hÃ m `predict_image` Ä‘á»ƒ dá»± Ä‘oÃ¡n lá»›p cá»§a áº£nh.
  5. Hiá»ƒn thá»‹ cÃ¡c thÃ´ng tin dá»± Ä‘oÃ¡n:
     - TÃªn file áº£nh.
     - KÃ­ch thÆ°á»›c gá»‘c cá»§a áº£nh.
     - KÃ­ch thÆ°á»›c áº£nh sau chuáº©n hÃ³a.
     - Lá»›p dá»± Ä‘oÃ¡n (cáº£ lá»›p nhá» vÃ  lá»›p lá»›n).
"""

# 7.5. Giao diá»‡n hiá»ƒn thá»‹ káº¿t quáº£ vÃ  xá»­ lÃ½ táº£i áº£nh
output_widget = widgets.Output()                                                         # Widget hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
loading_label = widgets.HTML(value="")                                                   # NhÃ£n hiá»ƒn thá»‹ tráº¡ng thÃ¡i "Äang tiáº¿n hÃ nh dá»± Ä‘oÃ¡n..."

def on_file_upload(change):
    """
    HÃ m xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng táº£i áº£nh lÃªn:
    - Hiá»ƒn thá»‹ tráº¡ng thÃ¡i "Äang tiáº¿n hÃ nh dá»± Ä‘oÃ¡n..."
    - Gá»i hÃ m dá»± Ä‘oÃ¡n vÃ  hiá»ƒn thá»‹ káº¿t quáº£.
    """
    uploaded_file = next(iter(change['new'].values()))                                   # Láº¥y file áº£nh Ä‘Æ°á»£c táº£i lÃªn
    image_path = uploaded_file['metadata']['name']
    with open(image_path, 'wb') as f:
        f.write(uploaded_file['content'])                                                # LÆ°u file áº£nh vÃ o Ä‘Æ°á»ng dáº«n

    # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i "Äang tiáº¿n hÃ nh dá»± Ä‘oÃ¡n..."
    loading_label.value = "<p style='font-size: 16px; color: #d32f2f;'>Äang tiáº¿n hÃ nh dá»± Ä‘oÃ¡n...</p>"

    # Dá»± Ä‘oÃ¡n káº¿t quáº£
    original_image, processed_size, predicted_index, predicted_class, predicted_coarse_class = predict_image(model, image_path)

    # Chuyá»ƒn Ä‘á»•i áº£nh gá»‘c sang Base64 Ä‘á»ƒ hiá»ƒn thá»‹
    buffer = BytesIO()
    original_image.save(buffer, format="PNG")
    img_base64_input = base64.b64encode(buffer.getvalue()).decode("utf-8")

    # MÃ´ phá»ng áº£nh Ä‘áº§u ra tá»« mÃ´ hÃ¬nh (dÃ¹ng áº£nh gá»‘c resize láº¡i trong trÆ°á»ng há»£p nÃ y)
    output_image = original_image.resize((32, 32))
    buffer_output = BytesIO()
    output_image.save(buffer_output, format="PNG")
    img_base64_output = base64.b64encode(buffer_output.getvalue()).decode("utf-8")

    # Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
    with output_widget:
        output_widget.clear_output()
        display(widgets.HTML(value=f"""
        <div style='
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            border: 5px solid #1565c0;
            border-radius: 15px;
            padding: 25px;
            max-width: 500px;
            margin: 0 auto;
            background-color: #ffffff;'>

            <h2 style='color: #1565c0; font-size: 18px; text-align:center;'>ğŸ¯ Káº¿t quáº£ dá»± Ä‘oÃ¡n</h2>
            <p style='font-size: 16px; color: #000000;'><b>TÃªn file áº£nh:</b> {uploaded_file['metadata']['name']}</p>
            <p style='font-size: 16px; color: #000000;'><b>KÃ­ch thÆ°á»›c gá»‘c:</b> {original_image.size}</p>
            <p style='font-size: 16px; color: #000000;'><b>KÃ­ch thÆ°á»›c sau chuáº©n hÃ³a:</b> {processed_size}</p>
            <p style='font-size: 16px; color: #000000;'><b>Vá»‹ trÃ­ lá»›p:</b> {predicted_index + 1} / 100</p>
            <p style='font-size: 16px; color: #000000;'><b>Lá»›p dá»± Ä‘oÃ¡n:</b>
                <span style='color:#d32f2f; font-weight:bold;'>{predicted_class}</span>
            </p>
            <p style='font-size: 16px; color: #000000;'><b>Thuá»™c lá»›p lá»›n:</b>
                <span style='color:#1565c0; font-weight:bold;'>{predicted_coarse_class}</span>
            </p>
            <div style="display: flex; justify-content: center; align-items: center; margin-top: 15px;">
                <div style="margin-right: 15px; text-align: center;">
                    <p style="font-size: 16px; font-weight: bold; color: #1565c0;">áº¢nh Ä‘áº§u vÃ o</p>
                    <img src="data:image/png;base64,{img_base64_input}" alt="áº¢nh Ä‘áº§u vÃ o" style="max-width: 150px; max-height: 150px; border-radius: 10px; border: 1px solid #ccc;"/>
                </div>
                <div style="text-align: center;">
                    <p style="font-size: 16px; font-weight: bold; color: #1565c0;">áº¢nh Ä‘áº§u ra</p>
                    <img src="data:image/png;base64,{img_base64_output}" alt="áº¢nh Ä‘áº§u ra" style="max-width: 150px; max-height: 150px; border-radius: 10px; border: 1px solid #ccc;"/>
                </div>
            </div>
        </div>
        """))

    # áº¨n thÃ´ng bÃ¡o "Äang tiáº¿n hÃ nh dá»± Ä‘oÃ¡n..."
    loading_label.value = ""

"""## **7.6. HÃ m táº¡o nÃºt upload áº£nh**
- **Chá»©c nÄƒng:** Táº¡o má»™t nÃºt táº£i áº£nh Ä‘á»ƒ ngÆ°á»i dÃ¹ng chá»n file áº£nh cáº§n dá»± Ä‘oÃ¡n.
- **MÃ´ táº£ chi tiáº¿t:**
  - Sá»­ dá»¥ng widget `FileUpload` Ä‘á»ƒ táº¡o giao diá»‡n táº£i áº£nh.
  - Cho phÃ©p ngÆ°á»i dÃ¹ng táº£i lÃªn má»™t áº£nh duy nháº¥t.
  - Káº¿t ná»‘i sá»± kiá»‡n táº£i áº£nh vá»›i hÃ m xá»­ lÃ½ `on_file_upload` Ä‘á»ƒ tá»± Ä‘á»™ng xá»­ lÃ½ vÃ  hiá»ƒn thá»‹ káº¿t quáº£.
"""

# 7.6. Táº¡o nÃºt upload áº£nh
upload_button = widgets.FileUpload(accept='image/*', multiple=False, description="Táº£i lÃªn")                  # NÃºt táº£i áº£nh vá»›i nhÃ£n "Táº£i lÃªn"
upload_button.observe(on_file_upload, names='value')

"""## **7.7. Táº£i mÃ´ hÃ¬nh vÃ  cháº¡y giao diá»‡n**
- **Chá»©c nÄƒng:** Táº£i mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  táº¡o giao diá»‡n Ä‘á»ƒ ngÆ°á»i dÃ¹ng dá»± Ä‘oÃ¡n.
- **Quy trÃ¬nh thá»±c hiá»‡n:**
  1. Kiá»ƒm tra thiáº¿t bá»‹ phÃ¹ há»£p Ä‘á»ƒ cháº¡y mÃ´ hÃ¬nh (GPU hoáº·c CPU).
  2. Táº£i mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« file checkpoint.
  3. XÃ¢y dá»±ng giao diá»‡n chÃ­nh bao gá»“m:
     - TiÃªu Ä‘á» vÃ  hÆ°á»›ng dáº«n sá»­ dá»¥ng.
     - NÃºt táº£i áº£nh.
     - VÃ¹ng hiá»ƒn thá»‹ tráº¡ng thÃ¡i dá»± Ä‘oÃ¡n.
     - VÃ¹ng hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n.
  4. Hiá»ƒn thá»‹ giao diá»‡n Ä‘á»ƒ ngÆ°á»i dÃ¹ng sá»­ dá»¥ng.
"""

# 7.7. Táº£i mÃ´ hÃ¬nh vÃ  hiá»ƒn thá»‹ giao diá»‡n
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")                                                         # Kiá»ƒm tra láº¡i GPU hay CPU
model = load_model(checkpoint_path)                                                                                           # Táº£i mÃ´ hÃ¬nh tá»« checkpoint á»Ÿ má»¥c 7.2.

# Táº¡o giao diá»‡n chÃ­nh
interface = widgets.VBox([
    widgets.HTML(value="<h3 style='color: #ffffff; font-size: 16px; text-align:center; padding: 10px; border-radius: 10px;'>ğŸŒŸ Táº£i hÃ¬nh áº£nh Ä‘á»ƒ thá»±c hiá»‡n dá»± Ä‘oÃ¡n:</h3>", layout=widgets.Layout(margin='0 0 20px 0')),
    widgets.HBox([upload_button], layout=widgets.Layout(justify_content='center', margin='0 0 20px 0')),                      # NÃºt táº£i áº£nh Ä‘Æ°á»£c cÄƒn giá»¯a
    loading_label,                                                                                                            # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i xá»­ lÃ½ dá»± Ä‘oÃ¡n
    output_widget                                                                                                             # Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
], layout=widgets.Layout(align_items='center', border_radius='10px', padding='20px', background_color='#f9f9f9'))

# Hiá»ƒn thá»‹ giao diá»‡n
display(interface)

"""# **8. Trá»±c quan hÃ³a káº¿t quáº£**

## **8.1. Xem dá»¯ liá»‡u tá»« file JSON**

### **Má»¥c tiÃªu**
- Äá»c file JSON Ä‘Ã£ lÆ°u thÃ´ng tin vá» káº¿t quáº£ huáº¥n luyá»‡n:
  - **Train Losses:** GiÃ¡ trá»‹ loss trung bÃ¬nh trÃªn táº­p huáº¥n luyá»‡n qua tá»«ng epoch.
  - **Validation Losses:** GiÃ¡ trá»‹ loss trung bÃ¬nh trÃªn táº­p validation qua tá»«ng epoch.
  - **Validation Accuracies:** Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation qua tá»«ng epoch.
  - **Epoch Times:** Thá»i gian huáº¥n luyá»‡n má»—i epoch.
  - **Best Accuracy:** Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c.
"""

# 8.1.. ÄÆ°á»ng dáº«n Ä‘áº¿n file JSON chá»©a dá»¯ liá»‡u huáº¥n luyá»‡n
json_file_path = '/content/drive/MyDrive/training_results.json'

# 8.1.1. Äá»c file JSON vÃ  náº¡p dá»¯ liá»‡u
with open(json_file_path, 'r') as f:
    training_data = json.load(f)

# 8.1.2. GÃ¡n dá»¯ liá»‡u vÃ o cÃ¡c biáº¿n Ä‘á»ƒ sá»­ dá»¥ng
train_losses = training_data["train_losses"]                                     # Loss trÃªn táº­p huáº¥n luyá»‡n
val_losses = training_data["val_losses"]                                         # Loss trÃªn táº­p validation
val_accuracies = training_data["val_accuracies"]                                 # Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation
epoch_times = training_data["epoch_times"]                                       # Thá»i gian huáº¥n luyá»‡n má»—i epoch
best_accuracy = training_data["best_accuracy"]                                   # Äá»™ chÃ­nh xÃ¡c cao nháº¥t

# 8.1,3. In ra thÃ´ng tin tá»« file JSON Ä‘á»ƒ kiá»ƒm tra
print(f"Train Losses: {train_losses[:5]} ...")                                   # Hiá»ƒn thá»‹ 5 giÃ¡ trá»‹ Ä‘áº§u tiÃªn cá»§a train_losses
print(f"Validation Losses: {val_losses[:5]} ...")
print(f"Validation Accuracies: {val_accuracies[:5]} ...")
print(f"Epoch Times: {epoch_times[:5]} ...")
print(f"Best Accuracy: {best_accuracy:.2f}%")

"""## **8.2. Xem dá»¯ liá»‡u tá»« file Checkpoint**

### **Má»¥c tiÃªu**
- Náº¡p thÃ´ng tin tá»« file checkpoint Ä‘Ã£ lÆ°u trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh, bao gá»“m:
  - **Model State Dict:** Tráº¡ng thÃ¡i cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u táº¡i thá»i Ä‘iá»ƒm checkpoint.
  - **Optimizer State Dict:** Tráº¡ng thÃ¡i cá»§a optimizer.
  - **Scheduler State Dict:** Tráº¡ng thÃ¡i cá»§a scheduler.
  - **Checkpoint Epoch:** Epoch táº¡i thá»i Ä‘iá»ƒm checkpoint.
  - **Best Validation Accuracy:** Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c trÃªn táº­p validation.
"""

# 8.2.1. ÄÆ°á»ng dáº«n checkpoint
checkpoint_path = '/content/drive/MyDrive/vgg11_best_checkpoint.pth'

# 8.2.2. Táº£i checkpoint
checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)

# 8.2.3. Náº¡p tráº¡ng thÃ¡i mÃ´ hÃ¬nh
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()  # Äáº·t mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡

# 8.2.4. Náº¡p tráº¡ng thÃ¡i optimizer
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

# 8.2.5. Náº¡p tráº¡ng thÃ¡i scheduler
scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

# 8.2.6. In thÃ´ng tin checkpoint
print(f"Checkpoint epoch: {checkpoint['epoch']}")
print(f"Best validation accuracy: {checkpoint['best_accuracy']:.2f}%")

"""## **8.3. Biá»ƒu Ä‘á»“ Loss**
### **A. Má»¥c tiÃªu**:
  - ÄÃ¡nh giÃ¡ quÃ¡ trÃ¬nh há»™i tá»¥ cá»§a mÃ´ hÃ¬nh qua tá»«ng epoch.
  - PhÃ¡t hiá»‡n cÃ¡c váº¥n Ä‘á» nhÆ° overfitting hoáº·c underfitting.

### **B. Nháº­n xÃ©t biá»ƒu Ä‘á»“**:
  - **Train Loss** giáº£m nhanh vÃ  tiá»‡m cáº­n 0, cho tháº¥y mÃ´ hÃ¬nh há»c tá»‘t trÃªn táº­p huáº¥n luyá»‡n.
  - **Validation Loss** á»•n Ä‘á»‹nh nhÆ°ng khÃ´ng giáº£m máº¡nh nhÆ° **Train Loss**, thá»ƒ hiá»‡n mÃ´ hÃ¬nh cÃ³ dáº¥u hiá»‡u overfitting.

"""

# 8.3. Váº½ biá»ƒu Ä‘á»“ Loss
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(train_losses) + 1), train_losses, label="Train Loss", color='blue', linewidth=1)
plt.plot(range(1, len(val_losses) + 1), val_losses, label="Validation Loss", color='orange', linewidth=1)
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("Loss", fontsize=14)
plt.title("Biá»ƒu Ä‘á»“ Loss qua tá»«ng Epoch", fontsize=16, fontweight="bold")
plt.legend(fontsize=12)
plt.grid(True)
plt.show()

"""## **8.4. Biá»ƒu Ä‘á»“ Accuracy**

### **A. Má»¥c tiÃªu**:
  - ÄÃ¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh qua tá»«ng epoch.
  - Kiá»ƒm tra sá»± cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation.

### **B. Nháº­n xÃ©t biá»ƒu Ä‘á»“**:
  - **Validation Accuracy** tÄƒng nhanh trong 50 epoch Ä‘áº§u, cho tháº¥y mÃ´ hÃ¬nh há»c tá»‘t vÃ  nhanh chÃ³ng cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.
  - Sau khoáº£ng epoch 200, **Validation Accuracy** á»•n Ä‘á»‹nh vÃ  tiá»‡m cáº­n 70%, thá»ƒ hiá»‡n mÃ´ hÃ¬nh Ä‘áº¡t má»©c há»™i tá»¥ tá»‘t.
  - KhÃ´ng cÃ³ hiá»‡n tÆ°á»£ng giáº£m Ä‘á»™ chÃ­nh xÃ¡c Ä‘Ã¡ng ká»ƒ, cho tháº¥y mÃ´ hÃ¬nh khÃ´ng bá»‹ overfitting nghiÃªm trá»ng.
"""

# Váº½ biá»ƒu Ä‘á»“ Accuracy vá»›i cáº£i thiá»‡n chÃº thÃ­ch
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label="Validation Accuracy", color='green', linewidth=0.6)

# TÃ¬m epoch cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
max_acc = max(val_accuracies)                                                                                          # GiÃ¡ trá»‹ cao nháº¥t
max_epoch = val_accuracies.index(max_acc) + 1                                                                          # Epoch tÆ°Æ¡ng á»©ng (cá»™ng 1 vÃ¬ index báº¯t Ä‘áº§u tá»« 0)

# ThÃªm Ä‘iá»ƒm Ä‘Ã¡nh dáº¥u nhá» hÆ¡n táº¡i giÃ¡ trá»‹ cao nháº¥t
plt.scatter(max_epoch, max_acc, color='red', s=70, zorder=5, label=f"Highest Accuracy ({max_acc:.2f}%)")

# ThÃªm Ä‘Æ°á»ng chá»‰ dáº«n (arrow) tá»›i Ä‘iá»ƒm cao nháº¥t vÃ  Ä‘iá»u chá»‰nh vá»‹ trÃ­ chÃº thÃ­ch
plt.annotate(
    f"{max_acc:.2f}%",                                                                                                 # Ná»™i dung chÃº thÃ­ch
    xy=(max_epoch, max_acc),                                                                                           # Tá»a Ä‘á»™ Ä‘áº§u (Ä‘iá»ƒm Ä‘Ã¡nh dáº¥u)
    xytext=(max_epoch - 40, max_acc - 7),                                                                              # Äáº©y chÃº thÃ­ch xa hÆ¡n (Ä‘iá»u chá»‰nh tá»a Ä‘á»™ cuá»‘i)
    arrowprops=dict(facecolor='black', arrowstyle="->", lw=1.5),                                                       # Äá»‹nh dáº¡ng mÅ©i tÃªn
    fontsize=12, color='black', ha='center'                                                                            # Äá»‹nh dáº¡ng chá»¯
)

# Äá»‹nh dáº¡ng biá»ƒu Ä‘á»“
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("Accuracy (%)", fontsize=14)
plt.title("Biá»ƒu Ä‘á»“ Accuracy qua tá»«ng Epoch", fontsize=16, fontweight="bold")
plt.legend(fontsize=12, loc='lower right')                                                                             # Äáº·t chÃº thÃ­ch á»Ÿ gÃ³c dÆ°á»›i pháº£i
plt.grid(True, linestyle='--', alpha=0.7)                                                                              # ThÃªm lÆ°á»›i vá»›i Ä‘á»™ má»
plt.tight_layout()                                                                                                     # Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh Ä‘á»ƒ khÃ´ng bá»‹ trÃ n
plt.show()

"""## **8.5. Biá»ƒu Ä‘á»“ thá»i gian huáº¥n luyá»‡n**

### **A. Má»¥c tiÃªu**:
  - Trá»±c quan hÃ³a thá»i gian huáº¥n luyá»‡n cá»§a má»—i epoch.
  - XÃ¡c Ä‘á»‹nh thá»i gian huáº¥n luyá»‡n nhanh nháº¥t vÃ  cháº­m nháº¥t.
  - PhÃ¢n tÃ­ch thá»i gian huáº¥n luyá»‡n cá»§a epoch cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t.

### **B. Nháº­n xÃ©t biá»ƒu Ä‘á»“**:
  - Thá»i gian huáº¥n luyá»‡n dao Ä‘á»™ng qua tá»«ng epoch, phá»¥ thuá»™c vÃ o tÃ­nh toÃ¡n GPU/CPU vÃ  dá»¯ liá»‡u.
  - Epoch nhanh nháº¥t vÃ  cháº­m nháº¥t cÃ³ thá»ƒ giÃºp tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t huáº¥n luyá»‡n.
  - Thá»i gian huáº¥n luyá»‡n cá»§a epoch cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t cÅ©ng lÃ  má»™t tham chiáº¿u quan trá»ng.
"""

# TÃ¬m thá»i gian huáº¥n luyá»‡n nhanh nháº¥t, cháº­m nháº¥t vÃ  cá»§a epoch cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
min_time = min(epoch_times)                                                                                      # Thá»i gian tháº¥p nháº¥t
max_time = max(epoch_times)                                                                                      # Thá»i gian cao nháº¥t
min_time_epoch = epoch_times.index(min_time) + 1                                                                 # Epoch tÆ°Æ¡ng á»©ng vá»›i thá»i gian tháº¥p nháº¥t
max_time_epoch = epoch_times.index(max_time) + 1                                                                 # Epoch tÆ°Æ¡ng á»©ng vá»›i thá»i gian cao nháº¥t
best_acc_epoch = val_accuracies.index(best_accuracy) + 1                                                         # Epoch cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
best_acc_epoch_time = epoch_times[best_acc_epoch - 1]                                                            # Thá»i gian cá»§a epoch cÃ³ % cao nháº¥t

# Váº½ biá»ƒu Ä‘á»“ thá»i gian huáº¥n luyá»‡n qua tá»«ng epoch vá»›i cÃ¡c Ä‘iá»ƒm Ä‘Ã¡nh dáº¥u rÃµ rÃ ng
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(epoch_times) + 1), epoch_times, label="Thá»i gian tá»«ng Epoch", color='blue', linewidth=0.4)

# ÄÃ¡nh dáº¥u thá»i gian nhanh nháº¥t vÃ  cháº­m nháº¥t
plt.scatter(min_time_epoch, min_time, color='green', s=70, zorder=5,
            label=f"Epoch nhanh nháº¥t (Epoch {min_time_epoch}, {min_time:.2f}s)")
plt.scatter(max_time_epoch, max_time, color='red', s=70, zorder=5,
            label=f"Epoch cháº­m nháº¥t (Epoch {max_time_epoch}, {max_time:.2f}s)")

# ÄÃ¡nh dáº¥u thá»i gian cá»§a epoch cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
plt.scatter(best_acc_epoch, best_acc_epoch_time, color='orange', s=70, zorder=5,
            label=f"Äá»™ chÃ­nh xÃ¡c cao nháº¥t (Epoch {best_acc_epoch}, {best_acc_epoch_time:.2f}s)")

# ThÃªm Ä‘Æ°á»ng chá»‰ dáº«n (arrow) cho cÃ¡c Ä‘iá»ƒm Ä‘Ã¡nh dáº¥u vÃ  chá»‰nh vá»‹ trÃ­ hiá»ƒn thá»‹
plt.annotate(f"{min_time:.2f}s", xy=(min_time_epoch, min_time),
             xytext=(min_time_epoch - 15, min_time + 2),                                                          # Chá»‰nh vá»‹ trÃ­ xa khá»i Ä‘Æ°á»ng
             arrowprops=dict(facecolor='green', arrowstyle="->"), fontsize=10, color='green')
plt.annotate(f"{max_time:.2f}s", xy=(max_time_epoch, max_time),
             xytext=(max_time_epoch + 15, max_time - 2),                                                          # Chá»‰nh vá»‹ trÃ­ xa khá»i Ä‘Æ°á»ng
             arrowprops=dict(facecolor='red', arrowstyle="->"), fontsize=10, color='red')
plt.annotate(f"{best_acc_epoch_time:.2f}s", xy=(best_acc_epoch, best_acc_epoch_time),
             xytext=(best_acc_epoch + 20, best_acc_epoch_time + 2),                                               # Chá»‰nh vá»‹ trÃ­ xa hÆ¡n
             arrowprops=dict(facecolor='orange', arrowstyle="->"), fontsize=10, color='orange')

# Äá»‹nh dáº¡ng biá»ƒu Ä‘á»“
plt.xlabel("Sá»‘ lÆ°á»£ng Epoch", fontsize=14)
plt.ylabel("Thá»i gian (giÃ¢y)", fontsize=14)
plt.title("Thá»i gian huáº¥n luyá»‡n qua tá»«ng Epoch", fontsize=16, fontweight="bold")
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()                                                                                                # Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh Ä‘á»ƒ khÃ´ng bá»‹ trÃ n
plt.show()